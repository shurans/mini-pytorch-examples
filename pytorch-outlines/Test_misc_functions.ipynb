{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "camera_normal = np.zeros([3, 2, 2], dtype=np.float32)\n",
    "camera_normal[:,0,0] = 1\n",
    "camera_normal[:,0,1] = 2\n",
    "camera_normal[:,1,0] = 3\n",
    "camera_normal[:,1,1] = 4\n",
    "\n",
    "print(camera_normal)\n",
    "print(camera_normal[:,1,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_normal = np.zeros([2, 2, 3], dtype=np.float32)\n",
    "camera_normal[0,0,:] = 1\n",
    "camera_normal[0,1,:] = 2\n",
    "camera_normal[1,0,:] = 3\n",
    "camera_normal[1,1,:] = 4\n",
    "\n",
    "print(camera_normal)\n",
    "print(camera_normal[1,1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from data_loader import Dataset,Options\n",
    "\n",
    "# from skimage.transform import resize\n",
    "import skimage\n",
    "\n",
    "\n",
    "exr_arr = np.load('data/surface-normals-converted/000000000-normals.exr.npy')\n",
    "exr_arr[exr_arr>1] = 1\n",
    "exr_arr[exr_arr<-1] = -1\n",
    "\n",
    "print('orig surface normals shape:')\n",
    "print(exr_arr.shape)\n",
    "exr_arr = exr_arr.transpose(1,2,0)\n",
    "plt.imshow(exr_arr)\n",
    "plt.show()\n",
    "\n",
    "# Resize the surface normals\n",
    "exr_arr_cropped = skimage.transform.resize(exr_arr, (244, 244))\n",
    "plt.imshow(exr_arr_cropped)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Edge Detection on Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from data_loader import Dataset\n",
    "import OpenEXR, Imath\n",
    "from scipy.misc import imsave\n",
    "\n",
    "import sys\n",
    "sys.path.append('../pytorch-normals/')\n",
    "import data_processing_script\n",
    "\n",
    "class OPT():\n",
    "    def __init__(self):\n",
    "        self.dataroot = './data/'\n",
    "        self.file_list = './data/datalist'\n",
    "        self.batchSize = 32\n",
    "        self.shuffle = True\n",
    "        self.phase = 'train'\n",
    "        self.num_epochs = 500\n",
    "        self.imsize = 224\n",
    "        self.num_classes = int(3)\n",
    "        self.gpu = '0'\n",
    "        self.logs_path = 'logs/exp9'\n",
    "        self.use_pretrained = False\n",
    "\n",
    "opt = OPT()\n",
    "\n",
    "###################### DataLoader #############################\n",
    "dataloader = Dataset(opt)\n",
    "\n",
    "\n",
    "depth_path = '/media/shrek/work/datasets/google-warehouse/bottles/complete-set/data/source-files/depth-imgs/%09d-depth.exr'\n",
    "edges_output_path = 'data/train/edges-depth-imgs/%09d-depth-edges.jpg'\n",
    "\n",
    "for i in range (1,100):\n",
    "    # Load Depth Img and Apply Blur\n",
    "    print('Loading img %d'%(i))\n",
    "    depth_img_orig = data_processing_script.exr_loader(depth_path%(i), ndim=1)\n",
    "    depth_img_orig = cv2.GaussianBlur(depth_img_orig,(5,5),0)\n",
    "    \n",
    "    # Make all depth values greater than 2.5m as 0 (for masking edge matrix)\n",
    "    depth_img_mask = depth_img_orig.copy()\n",
    "    depth_img_mask[depth_img_mask > 2.5]=0\n",
    "    depth_img_mask[depth_img_mask > 0 ]=1\n",
    "    \n",
    "    # Apply Laplacian filters for edge detection\n",
    "    edges_lap = cv2.Laplacian(depth_img_orig, cv2.CV_64F, ksize=7, borderType=0 )\n",
    "    edges_lap = (np.absolute(edges_lap).astype(np.uint8))\n",
    "    edges_lap_binary = edges_lap.copy()\n",
    "    print(edges_lap_binary.max())\n",
    "    edges_lap_binary[edges_lap_binary>1] = 255\n",
    "    edges_lap_binary[edges_lap_binary<=1] = 0\n",
    "    edges_lap_binary = edges_lap_binary * depth_img_mask\n",
    "    \n",
    "    # Apply Canny filter\n",
    "    depth_img_masked = depth_img_orig * depth_img_mask\n",
    "    depth_img_masked *= 255.0/depth_img_masked.max()\n",
    "    depth_img_masked = np.uint8(depth_img_masked)\n",
    "    edges = cv2.Canny(depth_img_masked,5,10)\n",
    "    \n",
    "    display_output = 1\n",
    "    if(display_output):\n",
    "        fig1 = plt.figure(figsize=(12,12))\n",
    "        plt.imshow(depth_img_orig, cmap='gray')\n",
    "        plt.show()\n",
    "        fig2 = plt.figure(figsize=(12,12))\n",
    "        plt.imshow(edges_lap, cmap='gray')\n",
    "        plt.show()\n",
    "        fig3 = plt.figure(figsize=(12,12))\n",
    "        plt.imshow(edges_lap_binary, cmap='gray')\n",
    "        plt.show()\n",
    "        fig4 = plt.figure(figsize=(12,12))\n",
    "        plt.imshow(edges, cmap='gray')\n",
    "        plt.show()\n",
    "    \n",
    "\n",
    "    save_output = False\n",
    "    if(save_output):\n",
    "        imsave( edges_output_path%(i), edges_lap_binary )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Edge Detection on Surface Normals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from data_loader import Dataset\n",
    "import OpenEXR, Imath\n",
    "from scipy.misc import imsave\n",
    "import imageio\n",
    "\n",
    "class OPT():\n",
    "    def __init__(self):\n",
    "        self.dataroot = './data/'\n",
    "        self.file_list = './data/datalist'\n",
    "        self.batchSize = 32\n",
    "        self.shuffle = True\n",
    "        self.phase = 'train'\n",
    "        self.num_epochs = 500\n",
    "        self.imsize = 224\n",
    "        self.num_classes = int(3)\n",
    "        self.gpu = '0'\n",
    "        self.logs_path = 'logs/exp9'\n",
    "        self.use_pretrained = False\n",
    "\n",
    "opt = OPT()\n",
    "\n",
    "###################### DataLoader #############################\n",
    "dataloader = Dataset(opt)\n",
    "\n",
    "path_surface_normal_rgb = '/media/shrek/work/datasets/google-warehouse/bottles/complete-set/data/train/preprocessed-camera-normals/rgb-visualizations/%09d-cameraNormals.png'\n",
    "edges_output_path = '/media/shrek/work/datasets/google-warehouse/bottles/complete-set/data/train/preprocessed-camera-normals/edges-normals-imgs/%09d-normals-edges.jpg'\n",
    "\n",
    "for i in range (1,100):\n",
    "    # Load Depth Img and Apply Blur\n",
    "    print('Loading img %d'%(i))\n",
    "    surface_normal_rgb = imageio.imread(path_surface_normal_rgb%(i))\n",
    "    surface_normal_gray = cv2.cvtColor(surface_normal_rgb, cv2.COLOR_BGR2GRAY)\n",
    "    surface_normal_gray = cv2.GaussianBlur(surface_normal_gray,(5,5),0)\n",
    "    \n",
    "    # Try diff colorspace\n",
    "    surface_normal_hsv = cv2.cvtColor(surface_normal_rgb, cv2.COLOR_BGR2HSV)\n",
    "    surface_normal_hsv = surface_normal_hsv[:,:,1]\n",
    "    surface_normal_hsv = cv2.normalize(surface_normal_hsv, None, alpha=0, beta=255,\n",
    "                                       norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    surface_normal_gray = cv2.GaussianBlur(surface_normal_hsv,(5,5),0)\n",
    "    \n",
    "    \n",
    "    # Apply Laplacian filters for edge detection\n",
    "    edges_lap = cv2.Laplacian(surface_normal_gray, cv2.CV_64F, ksize=3, borderType=1 )\n",
    "    edges_lap = np.uint8(np.absolute(edges_lap)) \n",
    "    # Convert to binary \n",
    "    edges_lap_binary = edges_lap.copy()\n",
    "    edges_lap_binary[edges_lap_binary>15] = 255\n",
    "    edges_lap_binary[edges_lap_binary<=15] = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "#     # Apply Canny filter\n",
    "#     edges = cv2.Canny(surface_normal_gray,10,40)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Apply Sobel Filter\n",
    "    sobelx = cv2.Sobel(surface_normal_gray,cv2.CV_64F,1,0,ksize=1)\n",
    "    sobely = cv2.Sobel(surface_normal_gray,cv2.CV_64F,0,1,ksize=1)\n",
    "    sobelxy = sobelx + sobely\n",
    "    sobelxy = np.uint8(np.absolute(sobelxy))\n",
    "    # Convert to binary \n",
    "    edges_sobel_binary = sobelxy.copy()\n",
    "    edges_sobel_binary[edges_sobel_binary>15] = 255\n",
    "    edges_sobel_binary[edges_sobel_binary<=15] = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    display_output = 1\n",
    "    if(display_output):\n",
    "        fig0 = plt.figure(figsize=(12,12))\n",
    "        plt.imshow(surface_normal_rgb)\n",
    "        plt.show()\n",
    "        fig1 = plt.figure(figsize=(12,12))\n",
    "        plt.imshow(surface_normal_gray, cmap='gray')\n",
    "        plt.show()\n",
    "#         fig2 = plt.figure(figsize=(12,12))\n",
    "#         plt.imshow(edges_lap, cmap='gray')\n",
    "#         plt.show()\n",
    "#         fig3 = plt.figure(figsize=(12,12))\n",
    "#         plt.imshow(edges_lap_binary, cmap='gray')\n",
    "#         plt.show()\n",
    "        fig4 = plt.figure(figsize=(12,12))\n",
    "        plt.imshow(sobelxy, cmap='gray')\n",
    "        plt.show()\n",
    "        fig5 = plt.figure(figsize=(12,12))\n",
    "        plt.imshow(edges_sobel_binary, cmap='gray')\n",
    "        plt.show()\n",
    "    \n",
    "\n",
    "    save_output = False\n",
    "    if(save_output):\n",
    "        imsave( edges_output_path%(i), edges_lap_binary )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Pixel Values within Original depth2depth Weights examples\n",
    "# And generate and save own weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The two weights are equal =  True\n",
      "orig weights:\n",
      " [[   0    0    0 ...    0    0    0]\n",
      " [   0  773  803 ...  803 1000 1000]\n",
      " [   0  724  813 ...   38  954  965]\n",
      " ...\n",
      " [   0  482  551 ...  176  188  271]\n",
      " [   0  286  340 ...  199  271  242]\n",
      " [   0  139  132 ...  307  307  247]]\n",
      "my weights:\n",
      " [[   0    0    0 ...    0    0    0]\n",
      " [   0  773  803 ...  803 1000 1000]\n",
      " [   0  724  813 ...   38  954  965]\n",
      " ...\n",
      " [   0  482  551 ...  176  188  271]\n",
      " [   0  286  340 ...  199  271  242]\n",
      " [   0  139  132 ...  307  307  247]]\n",
      "My gen weights and weights from file are equal:  True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from PIL import Image \n",
    "import imageio\n",
    "from matplotlib import interactive\n",
    "interactive(True)\n",
    "%matplotlib qt  \n",
    "# %matplotlib inline \n",
    "\n",
    "# read in outlines/weights file\n",
    "prefix = 'realsense_004'\n",
    "path_outlines = 'data/depth2depth_sample_files/bound_realsense_test_bound/'+prefix+'_bound_est.png'\n",
    "path_weights = 'data/depth2depth_sample_files/bound_realsense_weight/'+prefix+'_weight.png'\n",
    "\n",
    "outlines = Image.open(path_outlines)\n",
    "outlines = np.array(outlines)\n",
    "weight_orig = Image.open(path_weights)\n",
    "weight_orig = np.array(weight_orig)\n",
    "\n",
    "\n",
    "# Create own weights\n",
    "outlines = outlines.astype(np.float64)/255\n",
    "weight = (1-outlines[:,:,1])\n",
    "weight = np.power(weight,3)\n",
    "weight = np.multiply(weight,1000)\n",
    "weight = np.rint(weight)\n",
    "weight = weight.astype(np.uint16)\n",
    "\n",
    "print('The two weights are equal = ', np.array_equal(weight_orig, weight))\n",
    "print('orig weights:\\n', weight_orig)\n",
    "print('my weights:\\n', weight)\n",
    "\n",
    "# Save my weights\n",
    "weight_save_path = 'data/depth2depth_sample_files/my_generated_weights/'+prefix+'_weight.png'\n",
    "array_buffer = weight.tobytes()\n",
    "img = Image.new(\"I\", weight.T.shape)\n",
    "img.frombytes(array_buffer, 'raw', 'I;16')\n",
    "img.save(weight_save_path)\n",
    "weight_from_file = Image.open(weight_save_path)\n",
    "weight_from_file = np.array(weight_from_file)\n",
    "print('My gen weights and weights from file are equal: ', np.array_equal(weight, weight_from_file))\n",
    "\n",
    "# Create interactive plot to analyze pixel values\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax0 = plt.subplot(141)\n",
    "ax1 = plt.subplot(142)\n",
    "ax2 = plt.subplot(143)\n",
    "ax3 = plt.subplot(144)\n",
    "\n",
    "ax0.imshow(outlines)\n",
    "ax0.set_title('Predicted Outlines')\n",
    "ax1.imshow(weight_orig)\n",
    "ax1.set_title('Orig Weights from \\n Outlines')\n",
    "ax2.imshow(weight)\n",
    "ax2.set_title('My Weights from \\n Outlines')\n",
    "ax3.imshow(weight_from_file)\n",
    "ax3.set_title('My Saved Weights')\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
