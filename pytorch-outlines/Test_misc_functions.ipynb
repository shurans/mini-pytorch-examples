{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1. 2.]\n",
      "  [3. 4.]]\n",
      "\n",
      " [[1. 2.]\n",
      "  [3. 4.]]\n",
      "\n",
      " [[1. 2.]\n",
      "  [3. 4.]]]\n",
      "[4. 4. 4.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "camera_normal = np.zeros([3, 2, 2], dtype=np.float32)\n",
    "camera_normal[:,0,0] = 1\n",
    "camera_normal[:,0,1] = 2\n",
    "camera_normal[:,1,0] = 3\n",
    "camera_normal[:,1,1] = 4\n",
    "\n",
    "print(camera_normal)\n",
    "print(camera_normal[:,1,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1. 1. 1.]\n",
      "  [2. 2. 2.]]\n",
      "\n",
      " [[3. 3. 3.]\n",
      "  [4. 4. 4.]]]\n",
      "[4. 4. 4.]\n"
     ]
    }
   ],
   "source": [
    "camera_normal = np.zeros([2, 2, 3], dtype=np.float32)\n",
    "camera_normal[0,0,:] = 1\n",
    "camera_normal[0,1,:] = 2\n",
    "camera_normal[1,0,:] = 3\n",
    "camera_normal[1,1,:] = 4\n",
    "\n",
    "print(camera_normal)\n",
    "print(camera_normal[1,1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Options'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-198ff5f0cce4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdata_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mOptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# from skimage.transform import resize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Options'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from data_loader import Dataset,Options\n",
    "\n",
    "# from skimage.transform import resize\n",
    "import skimage\n",
    "\n",
    "\n",
    "exr_arr = np.load('data/surface-normals-converted/000000000-normals.exr.npy')\n",
    "exr_arr[exr_arr>1] = 1\n",
    "exr_arr[exr_arr<-1] = -1\n",
    "\n",
    "print('orig surface normals shape:')\n",
    "print(exr_arr.shape)\n",
    "exr_arr = exr_arr.transpose(1,2,0)\n",
    "plt.imshow(exr_arr)\n",
    "plt.show()\n",
    "\n",
    "# Resize the surface normals\n",
    "exr_arr_cropped = skimage.transform.resize(exr_arr, (244, 244))\n",
    "plt.imshow(exr_arr_cropped)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Edge Detection on Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from data_loader import Dataset,Options\n",
    "import OpenEXR, Imath\n",
    "from scipy.misc import imsave\n",
    "\n",
    "class OPT():\n",
    "    def __init__(self):\n",
    "        self.dataroot = './data/'\n",
    "        self.file_list = './data/datalist'\n",
    "        self.batchSize = 32\n",
    "        self.shuffle = True\n",
    "        self.phase = 'train'\n",
    "        self.num_epochs = 500\n",
    "        self.imsize = 224\n",
    "        self.num_classes = int(3)\n",
    "        self.gpu = '0'\n",
    "        self.logs_path = 'logs/exp9'\n",
    "        self.use_pretrained = False\n",
    "\n",
    "opt = OPT()\n",
    "\n",
    "###################### DataLoader #############################\n",
    "dataloader = Dataset(opt)\n",
    "\n",
    "\n",
    "depth_path = '/media/shrek/work/datasets/google-warehouse/greppy-surface-normals-bottle-1500/dataset/%09d-depth.exr'\n",
    "edges_output_path = '/media/shrek/work/datasets/google-warehouse/greppy-surface-normals-bottle-1500/edges-depth-imgs/%09d-depth-edges.jpg'\n",
    "\n",
    "for i in range (1,100):\n",
    "    # Load Depth Img and Apply Blur\n",
    "    print('Loading img %d'%(i))\n",
    "    depth_img_orig = dataloader.exr_loader(depth_path%(i), ndim=1)\n",
    "    depth_img_orig = cv2.GaussianBlur(depth_img_orig,(5,5),0)\n",
    "    \n",
    "    # Make all depth values greater than 2.5m as 0 (for masking edge matrix)\n",
    "    depth_img_mask = depth_img_orig.copy()\n",
    "    depth_img_mask[depth_img_mask > 2.5]=0\n",
    "    depth_img_mask[depth_img_mask > 0 ]=1\n",
    "    \n",
    "    # Apply Laplacian filters for edge detection\n",
    "    edges_lap = cv2.Laplacian(depth_img_orig, cv2.CV_8U, ksize=7, borderType=0 )\n",
    "    edges_lap_binary = edges_lap.copy()\n",
    "    print(edges_lap_binary.max())\n",
    "    edges_lap_binary[edges_lap_binary>1] = 255\n",
    "    edges_lap_binary[edges_lap_binary<=1] = 0\n",
    "    edges_lap_binary = edges_lap_binary * depth_img_mask\n",
    "    \n",
    "    # Apply Canny filter\n",
    "    depth_img_masked = depth_img_orig * depth_img_mask\n",
    "    depth_img_masked *= 255.0/depth_img_masked.max()\n",
    "    depth_img_masked = np.uint8(depth_img_masked)\n",
    "    edges = cv2.Canny(depth_img_masked,5,10)\n",
    "    \n",
    "    display_output = 1\n",
    "    if(display_output):\n",
    "        fig1 = plt.figure(figsize=(12,12))\n",
    "        plt.imshow(depth_img_orig, cmap='gray')\n",
    "        plt.show()\n",
    "        fig2 = plt.figure(figsize=(12,12))\n",
    "        plt.imshow(edges_lap, cmap='gray')\n",
    "        plt.show()\n",
    "        fig3 = plt.figure(figsize=(12,12))\n",
    "        plt.imshow(edges_lap_binary, cmap='gray')\n",
    "        plt.show()\n",
    "#         fig4 = plt.figure(figsize=(12,12))\n",
    "#         plt.imshow(edges, cmap='gray')\n",
    "#         plt.show()\n",
    "    \n",
    "\n",
    "    save_output = True\n",
    "    if(save_output):\n",
    "        imsave( edges_output_path%(i), edges_lap_binary )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Edge Detection on Surface Normals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from data_loader import Dataset,Options\n",
    "import OpenEXR, Imath\n",
    "from scipy.misc import imsave\n",
    "import imageio\n",
    "\n",
    "class OPT():\n",
    "    def __init__(self):\n",
    "        self.dataroot = './data/'\n",
    "        self.file_list = './data/datalist'\n",
    "        self.batchSize = 32\n",
    "        self.shuffle = True\n",
    "        self.phase = 'train'\n",
    "        self.num_epochs = 500\n",
    "        self.imsize = 224\n",
    "        self.num_classes = int(3)\n",
    "        self.gpu = '0'\n",
    "        self.logs_path = 'logs/exp9'\n",
    "        self.use_pretrained = False\n",
    "\n",
    "opt = OPT()\n",
    "\n",
    "###################### DataLoader #############################\n",
    "dataloader = Dataset(opt)\n",
    "\n",
    "depth_path = '/media/shrek/work/datasets/google-warehouse/test-edges/preprocessed-camera-normals/%09d-cameraNormals.npy'\n",
    "depth_path_rgb = '/media/shrek/work/datasets/google-warehouse/test-edges/preprocessed-camera-normals/rgb-visualizations/%09d-cameraNormals.png'\n",
    "edges_output_path = '/media/shrek/work/datasets/google-warehouse/test-edges/preprocessed-camera-normals/edges-normals-imgs/%09d-normals-edges.jpg'\n",
    "\n",
    "for i in range (1,100):\n",
    "    # Load Depth Img and Apply Blur\n",
    "    print('Loading img %d'%(i))\n",
    "    #     depth_img_orig = np.load(depth_path%(i)).transpose(1,2,0)\n",
    "    depth_img_orig_rgb = imageio.imread(depth_path_rgb%(i))\n",
    "    depth_img_orig = cv2.cvtColor(depth_img_orig_rgb, cv2.COLOR_BGR2GRAY)\n",
    "    depth_img_orig = cv2.GaussianBlur(depth_img_orig,(5,5),0)\n",
    "    \n",
    "#     # Make all depth values greater than 2.5m as 0 (for masking edge matrix)\n",
    "#     depth_img_mask = depth_img_orig.copy()\n",
    "#     depth_img_mask[depth_img_mask > 2.5]=0\n",
    "#     depth_img_mask[depth_img_mask > 0 ]=1\n",
    "    \n",
    "    # Apply Laplacian filters for edge detection\n",
    "    edges_lap = cv2.Laplacian(depth_img_orig, cv2.CV_8U, ksize=3, borderType=1 )\n",
    "    edges_lap_binary = edges_lap.copy()\n",
    "    print(edges_lap_binary.max())\n",
    "    edges_lap_binary[edges_lap_binary>15] = 255\n",
    "    edges_lap_binary[edges_lap_binary<=10] = 0\n",
    "#     edges_lap_binary = edges_lap_binary * depth_img_mask\n",
    "    \n",
    "    # Apply Canny filter\n",
    "#     depth_img_masked = depth_img_orig * depth_img_mask\n",
    "#     depth_img_masked *= 255.0/depth_img_masked.max()\n",
    "#     depth_img_masked = np.uint8(depth_img_masked)\n",
    "    edges = cv2.Canny(depth_img_orig,10,40)\n",
    "    \n",
    "    display_output = 1\n",
    "    if(display_output):\n",
    "        fig1 = plt.figure(figsize=(12,12))\n",
    "        plt.imshow(depth_img_orig_rgb)\n",
    "        plt.show()\n",
    "        fig2 = plt.figure(figsize=(12,12))\n",
    "        plt.imshow(edges_lap, cmap='gray')\n",
    "        plt.show()\n",
    "        fig3 = plt.figure(figsize=(12,12))\n",
    "        plt.imshow(edges_lap_binary, cmap='gray')\n",
    "        plt.show()\n",
    "        fig4 = plt.figure(figsize=(12,12))\n",
    "        plt.imshow(edges, cmap='gray')\n",
    "        plt.show()\n",
    "    \n",
    "\n",
    "    save_output = True\n",
    "    if(save_output):\n",
    "        imsave( edges_output_path%(i), edges_lap_binary )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7403, -0.3435,  0.1837,  0.9554,  0.0386],\n",
      "        [-1.8947,  0.1641,  0.3512,  0.6326,  0.3800],\n",
      "        [ 0.1681,  0.9758,  1.0716, -0.1566,  0.2910]], requires_grad=True)\n",
      "torch.Size([3, 5])\n",
      "tensor([4, 1, 4])\n",
      "torch.Size([3])\n",
      "tensor(1.7672, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "print(input)\n",
    "print(input.shape)\n",
    "\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "print(target)\n",
    "print(target.shape)\n",
    "\n",
    "output = loss(input, target)\n",
    "print(output)\n",
    "\n",
    "\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640)\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "\n",
    "label_path = '/media/shrek/work/datasets/public/shuran-mini-pytorch-examples/nyuv2_test_class13/new_nyu_class13_0001.png'\n",
    "\n",
    "label = imageio.imread(label_path)\n",
    "\n",
    "print(label.shape)\n",
    "print(label.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Pixel Values within Original depth2depth Weights examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from PIL import Image \n",
    "import imageio\n",
    "from matplotlib import interactive\n",
    "interactive(True)\n",
    "%matplotlib qt  \n",
    "\n",
    "# read in outlines/weights file\n",
    "path_outlines = '/home/shrek/greppy/brain/transparent_detection/models/test_depth2depth/deepcompletion/data/bound_realsense_test_bound/realsense_004_bound_est.png'\n",
    "path_weights = '/home/shrek/greppy/brain/transparent_detection/models/test_depth2depth/deepcompletion/data/bound_realsense_weight/realsense_004_weight.png'\n",
    "\n",
    "outlines = Image.open(path_outlines)\n",
    "outlines = np.array(outlines)\n",
    "weights = Image.open(path_weights)\n",
    "weights = np.array(weights)\n",
    "\n",
    "\n",
    "\n",
    "# Create interactive plot to analyze pixel values\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax0 = plt.subplot(121)\n",
    "ax1 = plt.subplot(122)\n",
    "\n",
    "\n",
    "ax0.imshow(outlines)\n",
    "ax0.set_title('Predicted Outlines')\n",
    "ax1.imshow(weights)\n",
    "ax1.set_title('Weights from \\n Outlines')\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create weights and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "img_path = '/home/shrek/greppy/brain/transparent_detection/models/DeepCompletionRelease/torch/result/bound_realsense_test_bound/realsense_004_bound_est.png'\n",
    "\n",
    "# brain/surface-normals/references/DeepCompletionRelease/torch/result/bound_realsense_test_bound/realsense_004_bound_est.png\n",
    "\n",
    "file = Image.open(img_path)\n",
    "file_arr = np.array(file).astype(np.float64)/255\n",
    "weight = (1-file_arr[:,:,1])\n",
    "x = np.power(weight,3)\n",
    "x = np.multiply(x,1000)\n",
    "\n",
    "final_weight = x.astype(np.uint16)\n",
    "print(final_weight.shape)\n",
    "print(final_weight)\n",
    "\n",
    "# imageio.imwrite('weights.png', final_weight)\n",
    "array_buffer = final_weight.tobytes()\n",
    "img = Image.new(\"I\", final_weight.T.shape)\n",
    "img.frombytes(array_buffer, 'raw', 'I;16')\n",
    "img.save('weights_2.png')\n",
    "\n",
    "# imwrite(uint16(weight*1000), fullfile(output_dir, strrep(files(a).name, '_bound_est.png', '_weight.png')))\n",
    "\n",
    "\n",
    "\n",
    "# x = np.array([1,2,3])\n",
    "# y = np.array([1,2,3])\n",
    "\n",
    "# z = np.multiply(x,y)\n",
    "# print(z)\n",
    "# q = np.multiply(z,x)\n",
    "# print(q)\n",
    "\n",
    "\n",
    "path_img_test = '/home/shrek/greppy/brain/transparent_detection/models/DeepCompletionRelease/torch/result/bound_realsense_weight/realsense_004_weight.png'\n",
    "# path_img_train = 'data/train/edges-imgs/000000000-segmentation.png'\n",
    "\n",
    "weight = Image.open(path_img_test)\n",
    "weight = np.array(weight)\n",
    "print(weight)\n",
    "\n",
    "# weight = Image.open(path_img_train)\n",
    "# weight = np.array(weight)\n",
    "# print(weight)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
