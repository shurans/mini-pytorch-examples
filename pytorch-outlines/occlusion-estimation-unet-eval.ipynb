{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./models/')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from data_loader import Dataset\n",
    "import models.unet_normals as unet\n",
    "from PIL import Image \n",
    "import imageio\n",
    "from torchvision import transforms, utils\n",
    "import cv2\n",
    "%matplotlib inline \n",
    "\n",
    "\n",
    "class OPT():\n",
    "    def __init__(self):\n",
    "        self.dataroot = './data/'\n",
    "        self.file_list = './data/datalist'\n",
    "        self.weights_path = './data/results/weights'\n",
    "        self.batchSize = 1\n",
    "        self.shuffle = False\n",
    "        self.phase = 'eval'\n",
    "        self.num_epochs = 500\n",
    "        self.imsize = (288,512)\n",
    "        self.num_classes = int(3)\n",
    "        self.gpu = '0'\n",
    "        self.logs_path = 'logs/exp2'\n",
    "        self.use_pretrained = True\n",
    "\n",
    "opt = OPT()\n",
    "\n",
    "\n",
    "###################### Options #############################\n",
    "DIR_RESULTS = 'data/results/exp0/'\n",
    "DIR_WEIGHTS = 'data/results/exp0/weights_png/'\n",
    "DIR_WEIGHTS_VIZ = 'data/results/exp0/weights_png/rgb-visualizations/'\n",
    "\n",
    "phase = opt.phase\n",
    "device = torch.device(\"cuda:\"+ opt.gpu if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "###################### DataLoader #############################\n",
    "dataloader = Dataset(opt)\n",
    "\n",
    "\n",
    "###################### ModelBuilder #############################\n",
    "model = unet.Unet(num_classes=opt.num_classes)\n",
    "criterion = nn.CrossEntropyLoss(reduction='sum').to(device)\n",
    "\n",
    "# Load weights from checkpoint\n",
    "if (opt.use_pretrained == True):\n",
    "    checkpoint_path = 'logs/exp0/checkpoints/checkpoint-epoch_215.pth'\n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.0001)\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "\n",
    "def label_to_rgb(label):\n",
    "    '''Output RGB visualizations of the labels (outlines)\n",
    "    Assumes labels have int values and max number of classes = 3\n",
    "    \n",
    "    Args:\n",
    "        label (numpy.ndarray): Shape (height, width). Each pixel contains an int with value of class that it belongs to.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Shape (height, width, 3): RGB representation of the labels\n",
    "    '''\n",
    "    rgbArray = np.zeros((label.shape[0], label.shape[1], 3), dtype=np.uint8)\n",
    "    rgbArray[:, :, 0][label == 0] = 255\n",
    "    rgbArray[:, :, 1][label == 1] = 255\n",
    "    rgbArray[:, :, 2][label == 2] = 255\n",
    "    \n",
    "    return rgbArray\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run evaluation of the occlusion boundary model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "for i in range(int(dataloader.size()/opt.batchSize)):\n",
    "    # Get data\n",
    "    inputs, labels =  dataloader.get_batch()\n",
    "    \n",
    "    # Forward pass of the mini-batch\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    # Forward Prop\n",
    "    optimizer.zero_grad()\n",
    "    torch.set_grad_enabled(True)\n",
    "    logits = model(inputs)\n",
    "    \n",
    "    # calculating occlusion weights\n",
    "    logits_softmax = nn.Softmax(dim=1)(logits).detach().cpu().numpy().astype(np.float32)\n",
    "    file_arr = logits_softmax[0] # select the first img\n",
    "    weight = (1-file_arr[1,:,:])\n",
    "    x = np.power(weight,3)\n",
    "    x = np.multiply(x,1000)\n",
    "    final_weight = x.astype(np.uint16)\n",
    "    # Increase the min and max values by small amount epsilon so that it doesn't cause problem in depth2depth optimization code.\n",
    "    eps = 1\n",
    "    final_weight[final_weight==0] += eps\n",
    "    final_weight[final_weight==1000] -= eps\n",
    "    \n",
    "    # model predictions absolute - each pixel classified into a class\n",
    "    predictions = torch.max(logits, 1)[1].detach().cpu().numpy()\n",
    "    predictions = predictions[0]  # select the first img\n",
    "    predictions_color = label_to_rgb(predictions)\n",
    "    \n",
    "    #original rgb image\n",
    "    rgb_img = inputs.detach().cpu()\n",
    "    rgb_img = rgb_img[0] # select the first img\n",
    "    inv_normalize = transforms.Normalize(\n",
    "            mean=[-0.5/0.5, -0.5/0.5, -0.5/0.5],\n",
    "            std=[1/0.5, 1/0.5, 1/0.5]\n",
    "        )\n",
    "    rgb_img = inv_normalize(rgb_img)\n",
    "    rgb_img = rgb_img.numpy()\n",
    "    rgb_img = np.transpose(rgb_img, (1,2,0))\n",
    "    rgb_img = (rgb_img * 255).astype(np.uint8)\n",
    "    \n",
    "    #label\n",
    "    labels = labels.detach().cpu().squeeze().numpy()\n",
    "    labels_color = label_to_rgb(labels)\n",
    "    \n",
    "    # Save output results\n",
    "    final_weight_color =  np.array((1-file_arr[1,:,:])*255, dtype = np.uint8)\n",
    "    final_weight_color = np.expand_dims(final_weight_color, axis=2)\n",
    "    final_weight_color = cv2.applyColorMap(final_weight_color, cv2.COLORMAP_OCEAN)\n",
    "    final_weight_color = cv2.cvtColor(final_weight_color, cv2.COLOR_BGR2RGB)\n",
    "    result = np.concatenate([rgb_img, predictions_color, labels_color, final_weight_color], axis=1)\n",
    "    imageio.imwrite(os.path.join(DIR_RESULTS, '%04d-results.png' % (i)), result)\n",
    "    \n",
    "    # Display Results\n",
    "    print('Image %09d' % (i))\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(result)\n",
    "    plt.show()\n",
    "    \n",
    "    # Save weights file\n",
    "    array_buffer = final_weight.tobytes()\n",
    "    img = Image.new(\"I\", final_weight.T.shape)\n",
    "    img.frombytes(array_buffer, 'raw', 'I;16')\n",
    "    img.save(os.path.join(DIR_WEIGHTS, '%09d-occlusion-weight.png' % (i)))\n",
    "    \n",
    "    # Save weights rgb representation\n",
    "    imageio.imwrite(os.path.join(DIR_WEIGHTS_VIZ, '%09d-occlusion-weight-rgb.png' % (i)), final_weight_color)\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
