{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./models/')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from data_loader import Dataset,Options\n",
    "import models.unet_normals as unet\n",
    "from tensorboardX import SummaryWriter\n",
    "import OpenEXR, Imath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Options\n",
    "Set the various parameters:\n",
    "- dataroot: The folder where the training data is stored\n",
    "- file_list: List of filenames of images for training\n",
    "- batchSize: Batch size for model\n",
    "- shuffle: If true, will shuffle the dataset\n",
    "- phase: If 'train', then it's in training mode.\n",
    "- num_epochs: Number of epochs to train the model for\n",
    "- imsize: Dimensions of the image (square)\n",
    "- num_classes: Num of classes in the output\n",
    "- gpu: Which GPU device to use\n",
    "- logs_path: The path where the log files (tensorboard) will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OPT():\n",
    "    def __init__(self):\n",
    "        self.dataroot = './data/'\n",
    "        self.file_list = './data/datalist'\n",
    "        self.batchSize = 24\n",
    "        self.shuffle = True\n",
    "        self.phase = 'train'\n",
    "        self.num_epochs = 1000\n",
    "        self.imsize = 224\n",
    "        self.num_classes = int(3)\n",
    "        self.gpu = '0'\n",
    "        self.logs_path = 'logs/exp2'\n",
    "\n",
    "opt = OPT()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup logging and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffling the dataset\n"
     ]
    }
   ],
   "source": [
    "###################### Options #############################\n",
    "phase = opt.phase\n",
    "device = torch.device(\"cuda:\"+ opt.gpu if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "###################### TensorBoardX #############################\n",
    "if os.path.exists(opt.logs_path):\n",
    "    raise Exception('The folder \\\"{}\\\" already exists! Define a new log path or delete old contents.'.format(opt.logs_path))\n",
    "    \n",
    "writer = SummaryWriter(opt.logs_path, comment='create-graph')\n",
    "graph_created = False\n",
    "\n",
    "###################### DataLoader #############################\n",
    "dataloader = Dataset(opt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model\n",
    "We use a UNet model. The last few layers of this model are modified to return a 3 channel image, containing the x,y,z values of surface normal vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### ModelBuilder #############################\n",
    "model = unet.Unet(num_classes=opt.num_classes)\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "\n",
    "###################### Setup Optimazation #############################\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "###################### Loss fuction #############################\n",
    "'''\n",
    "@input: The 2 vectors whose cosine loss is to be calculated\n",
    "The dimensions of the matrices are expected to be (batchSize, 3, imsize, imsize). \n",
    "\n",
    "@return: \n",
    "elementwise_mean: will return the sum of all losses divided by num of elements\n",
    "none: The loss will be calculated to be of size (batchSize, imsize, imsize) containing cosine loss of each pixel\n",
    "'''\n",
    "def loss_fn(input_vec, target_vec, reduction='elementwise_mean'):\n",
    "    cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "    loss_val = 1.0 - cos(input_vec, target_vec)\n",
    "    if (reduction=='elementwise_mean'):\n",
    "        return torch.mean(loss_val)\n",
    "    elif (reduction=='none'):\n",
    "        return loss_val\n",
    "    else:\n",
    "        raise Exception('Warning! The reduction is invalid. Please use \\'elementwise_mean\\' or \\'none\\''.format())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/999\n",
      "----------\n",
      "train Loss: 0.6568\n",
      "Epoch 1/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.1148\n",
      "Epoch 2/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.1049\n",
      "Epoch 3/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0976\n",
      "Epoch 4/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.1011\n",
      "Epoch 5/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0926\n",
      "Epoch 6/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0968\n",
      "Epoch 7/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0911\n",
      "Epoch 8/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.1023\n",
      "Epoch 9/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0828\n",
      "Epoch 10/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0896\n",
      "Epoch 11/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.1203\n",
      "Epoch 12/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0673\n",
      "Epoch 13/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.1067\n",
      "Epoch 14/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.1147\n",
      "Epoch 15/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0827\n",
      "Epoch 16/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0901\n",
      "Epoch 17/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.1030\n",
      "Epoch 18/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0804\n",
      "Epoch 19/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.1001\n",
      "Epoch 20/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.1099\n",
      "Epoch 21/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0881\n",
      "Epoch 22/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0972\n",
      "Epoch 23/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0910\n",
      "Epoch 24/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0996\n",
      "Epoch 25/999\n",
      "----------\n",
      "train Loss: 0.0941\n",
      "Epoch 26/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0975\n",
      "Epoch 27/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0963\n",
      "Epoch 28/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0925\n",
      "Epoch 29/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0920\n",
      "Epoch 30/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0933\n",
      "Epoch 31/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.1063\n",
      "Epoch 32/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0707\n",
      "Epoch 33/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.1195\n",
      "Epoch 34/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0967\n",
      "Epoch 35/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0819\n",
      "Epoch 36/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.1093\n",
      "Epoch 37/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0988\n",
      "Epoch 38/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0950\n",
      "Epoch 39/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0859\n",
      "Epoch 40/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.1108\n",
      "Epoch 41/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0877\n",
      "Epoch 42/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0966\n",
      "Epoch 43/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0906\n",
      "Epoch 44/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.1102\n",
      "Epoch 45/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0828\n",
      "Epoch 46/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.1016\n",
      "Epoch 47/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0890\n",
      "Epoch 48/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0937\n",
      "Epoch 49/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0978\n",
      "Epoch 50/999\n",
      "----------\n",
      "train Loss: 0.0974\n",
      "Epoch 51/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0976\n",
      "Epoch 52/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0915\n",
      "Epoch 53/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0967\n",
      "Epoch 54/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0877\n",
      "Epoch 55/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.1073\n",
      "Epoch 56/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0985\n",
      "Epoch 57/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0952\n",
      "Epoch 58/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0935\n",
      "Epoch 59/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0856\n",
      "Epoch 60/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.1030\n",
      "Epoch 61/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0931\n",
      "Epoch 62/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0909\n",
      "Epoch 63/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0933\n",
      "Epoch 64/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0928\n",
      "Epoch 65/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0972\n",
      "Epoch 66/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0957\n",
      "Epoch 67/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0938\n",
      "Epoch 68/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.1050\n",
      "Epoch 69/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0877\n",
      "Epoch 70/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0906\n",
      "Epoch 71/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0997\n",
      "Epoch 72/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0944\n",
      "Epoch 73/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0966\n",
      "Epoch 74/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0958\n",
      "Epoch 75/999\n",
      "----------\n",
      "train Loss: 0.0962\n",
      "Epoch 76/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0952\n",
      "Epoch 77/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0978\n",
      "Epoch 78/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0899\n",
      "Epoch 79/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0927\n",
      "Epoch 80/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0878\n",
      "Epoch 81/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.1064\n",
      "Epoch 82/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.1104\n",
      "Epoch 83/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0763\n",
      "Epoch 84/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0947\n",
      "Epoch 85/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0940\n",
      "Epoch 86/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.1087\n",
      "Epoch 87/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0873\n",
      "Epoch 88/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0954\n",
      "Epoch 89/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0844\n",
      "Epoch 90/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.1000\n",
      "Epoch 91/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.1130\n",
      "Epoch 92/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0811\n",
      "Epoch 93/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0954\n",
      "Epoch 94/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.1038\n",
      "Epoch 95/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0899\n",
      "Epoch 96/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0836\n",
      "Epoch 97/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.1018\n",
      "Epoch 98/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0954\n",
      "Epoch 99/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0889\n",
      "Epoch 100/999\n",
      "----------\n",
      "train Loss: 0.0958\n",
      "Epoch 101/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0896\n",
      "Epoch 102/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.1009\n",
      "Epoch 103/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0834\n",
      "Epoch 104/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.1023\n",
      "Epoch 105/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0959\n",
      "Epoch 106/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0889\n",
      "Epoch 107/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0966\n",
      "Epoch 108/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0729\n",
      "Epoch 109/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.1080\n",
      "Epoch 110/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.1049\n",
      "Epoch 111/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0813\n",
      "Epoch 112/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0952\n",
      "Epoch 113/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0790\n",
      "Epoch 114/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0913\n",
      "Epoch 115/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0971\n",
      "Epoch 116/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.1082\n",
      "Epoch 117/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0747\n",
      "Epoch 118/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.1031\n",
      "Epoch 119/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0895\n",
      "Epoch 120/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0911\n",
      "Epoch 121/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.1025\n",
      "Epoch 122/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0804\n",
      "Epoch 123/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0936\n",
      "Epoch 124/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0922\n",
      "Epoch 125/999\n",
      "----------\n",
      "train Loss: 0.0939\n",
      "Epoch 126/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0819\n",
      "Epoch 127/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.1007\n",
      "Epoch 128/999\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffling the dataset\n",
      "train Loss: 0.0877\n",
      "Epoch 129/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0806\n",
      "Epoch 130/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0969\n",
      "Epoch 131/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0937\n",
      "Epoch 132/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0882\n",
      "Epoch 133/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0860\n",
      "Epoch 134/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0798\n",
      "Epoch 135/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.1046\n",
      "Epoch 136/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0955\n",
      "Epoch 137/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0766\n",
      "Epoch 138/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0959\n",
      "Epoch 139/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0684\n",
      "Epoch 140/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0887\n",
      "Epoch 141/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.1006\n",
      "Epoch 142/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0850\n",
      "Epoch 143/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0894\n",
      "Epoch 144/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0806\n",
      "Epoch 145/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0798\n",
      "Epoch 146/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0865\n",
      "Epoch 147/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0844\n",
      "Epoch 148/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0815\n",
      "Epoch 149/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0842\n",
      "Epoch 150/999\n",
      "----------\n",
      "train Loss: 0.0824\n",
      "Epoch 151/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0863\n",
      "Epoch 152/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0842\n",
      "Epoch 153/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0753\n",
      "Epoch 154/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0720\n",
      "Epoch 155/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.1001\n",
      "Epoch 156/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0720\n",
      "Epoch 157/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0813\n",
      "Epoch 158/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0736\n",
      "Epoch 159/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0829\n",
      "Epoch 160/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0744\n",
      "Epoch 161/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0733\n",
      "Epoch 162/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0783\n",
      "Epoch 163/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0825\n",
      "Epoch 164/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0648\n",
      "Epoch 165/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0788\n",
      "Epoch 166/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0730\n",
      "Epoch 167/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0741\n",
      "Epoch 168/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0887\n",
      "Epoch 169/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0664\n",
      "Epoch 170/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0769\n",
      "Epoch 171/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0732\n",
      "Epoch 172/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0758\n",
      "Epoch 173/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0698\n",
      "Epoch 174/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0719\n",
      "Epoch 175/999\n",
      "----------\n",
      "train Loss: 0.0689\n",
      "Epoch 176/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0751\n",
      "Epoch 177/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0629\n",
      "Epoch 178/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0685\n",
      "Epoch 179/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0773\n",
      "Epoch 180/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0696\n",
      "Epoch 181/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0749\n",
      "Epoch 182/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0668\n",
      "Epoch 183/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0842\n",
      "Epoch 184/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0772\n",
      "Epoch 185/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0759\n",
      "Epoch 186/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0682\n",
      "Epoch 187/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0808\n",
      "Epoch 188/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0615\n",
      "Epoch 189/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0817\n",
      "Epoch 190/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0774\n",
      "Epoch 191/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0590\n",
      "Epoch 192/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0626\n",
      "Epoch 193/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0708\n",
      "Epoch 194/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0831\n",
      "Epoch 195/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0668\n",
      "Epoch 196/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0600\n",
      "Epoch 197/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0644\n",
      "Epoch 198/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0693\n",
      "Epoch 199/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0613\n",
      "Epoch 200/999\n",
      "----------\n",
      "train Loss: 0.0663\n",
      "Epoch 201/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0648\n",
      "Epoch 202/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0644\n",
      "Epoch 203/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0589\n",
      "Epoch 204/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0672\n",
      "Epoch 205/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0633\n",
      "Epoch 206/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0624\n",
      "Epoch 207/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0532\n",
      "Epoch 208/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0742\n",
      "Epoch 209/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0680\n",
      "Epoch 210/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0616\n",
      "Epoch 211/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0610\n",
      "Epoch 212/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0647\n",
      "Epoch 213/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0601\n",
      "Epoch 214/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0630\n",
      "Epoch 215/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0571\n",
      "Epoch 216/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0639\n",
      "Epoch 217/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0562\n",
      "Epoch 218/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0637\n",
      "Epoch 219/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0557\n",
      "Epoch 220/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0632\n",
      "Epoch 221/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0685\n",
      "Epoch 222/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0535\n",
      "Epoch 223/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0659\n",
      "Epoch 224/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0562\n",
      "Epoch 225/999\n",
      "----------\n",
      "train Loss: 0.0543\n",
      "Epoch 226/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0655\n",
      "Epoch 227/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0523\n",
      "Epoch 228/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0630\n",
      "Epoch 229/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0543\n",
      "Epoch 230/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0572\n",
      "Epoch 231/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0570\n",
      "Epoch 232/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0545\n",
      "Epoch 233/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0541\n",
      "Epoch 234/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0524\n",
      "Epoch 235/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0600\n",
      "Epoch 236/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0507\n",
      "Epoch 237/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0537\n",
      "Epoch 238/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0511\n",
      "Epoch 239/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0530\n",
      "Epoch 240/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0512\n",
      "Epoch 241/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0542\n",
      "Epoch 242/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0427\n",
      "Epoch 243/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0538\n",
      "Epoch 244/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0492\n",
      "Epoch 245/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0526\n",
      "Epoch 246/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0484\n",
      "Epoch 247/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0461\n",
      "Epoch 248/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0530\n",
      "Epoch 249/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0469\n",
      "Epoch 250/999\n",
      "----------\n",
      "train Loss: 0.0506\n",
      "Epoch 251/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0484\n",
      "Epoch 252/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0477\n",
      "Epoch 253/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0471\n",
      "Epoch 254/999\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffling the dataset\n",
      "train Loss: 0.0500\n",
      "Epoch 255/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0449\n",
      "Epoch 256/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0477\n",
      "Epoch 257/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0534\n",
      "Epoch 258/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0454\n",
      "Epoch 259/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0460\n",
      "Epoch 260/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0458\n",
      "Epoch 261/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0472\n",
      "Epoch 262/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0502\n",
      "Epoch 263/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0472\n",
      "Epoch 264/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0462\n",
      "Epoch 265/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0420\n",
      "Epoch 266/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0534\n",
      "Epoch 267/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0424\n",
      "Epoch 268/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0426\n",
      "Epoch 269/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0496\n",
      "Epoch 270/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0421\n",
      "Epoch 271/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0482\n",
      "Epoch 272/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0447\n",
      "Epoch 273/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0448\n",
      "Epoch 274/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0464\n",
      "Epoch 275/999\n",
      "----------\n",
      "train Loss: 0.0458\n",
      "Epoch 276/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0469\n",
      "Epoch 277/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0466\n",
      "Epoch 278/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0455\n",
      "Epoch 279/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0423\n",
      "Epoch 280/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0506\n",
      "Epoch 281/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0419\n",
      "Epoch 282/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0431\n",
      "Epoch 283/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0458\n",
      "Epoch 284/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0443\n",
      "Epoch 285/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0421\n",
      "Epoch 286/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0405\n",
      "Epoch 287/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0434\n",
      "Epoch 288/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0520\n",
      "Epoch 289/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0419\n",
      "Epoch 290/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0475\n",
      "Epoch 291/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0487\n",
      "Epoch 292/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0471\n",
      "Epoch 293/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0410\n",
      "Epoch 294/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0498\n",
      "Epoch 295/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0482\n",
      "Epoch 296/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0439\n",
      "Epoch 297/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0507\n",
      "Epoch 298/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0462\n",
      "Epoch 299/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0475\n",
      "Epoch 300/999\n",
      "----------\n",
      "train Loss: 0.0454\n",
      "Epoch 301/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0450\n",
      "Epoch 302/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0435\n",
      "Epoch 303/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0431\n",
      "Epoch 304/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0469\n",
      "Epoch 305/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0455\n",
      "Epoch 306/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0427\n",
      "Epoch 307/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0429\n",
      "Epoch 308/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0463\n",
      "Epoch 309/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0438\n",
      "Epoch 310/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0397\n",
      "Epoch 311/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0372\n",
      "Epoch 312/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0450\n",
      "Epoch 313/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0381\n",
      "Epoch 314/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0486\n",
      "Epoch 315/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0320\n",
      "Epoch 316/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0420\n",
      "Epoch 317/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0399\n",
      "Epoch 318/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0378\n",
      "Epoch 319/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0393\n",
      "Epoch 320/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0395\n",
      "Epoch 321/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0392\n",
      "Epoch 322/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0359\n",
      "Epoch 323/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0375\n",
      "Epoch 324/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0375\n",
      "Epoch 325/999\n",
      "----------\n",
      "train Loss: 0.0372\n",
      "Epoch 326/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0353\n",
      "Epoch 327/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0381\n",
      "Epoch 328/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0338\n",
      "Epoch 329/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0362\n",
      "Epoch 330/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0370\n",
      "Epoch 331/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0314\n",
      "Epoch 332/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0393\n",
      "Epoch 333/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0356\n",
      "Epoch 334/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0395\n",
      "Epoch 335/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0352\n",
      "Epoch 336/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0317\n",
      "Epoch 337/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0332\n",
      "Epoch 338/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0364\n",
      "Epoch 339/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0348\n",
      "Epoch 340/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0323\n",
      "Epoch 341/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0375\n",
      "Epoch 342/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0347\n",
      "Epoch 343/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0330\n",
      "Epoch 344/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0346\n",
      "Epoch 345/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0357\n",
      "Epoch 346/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0340\n",
      "Epoch 347/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0337\n",
      "Epoch 348/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0330\n",
      "Epoch 349/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0341\n",
      "Epoch 350/999\n",
      "----------\n",
      "train Loss: 0.0340\n",
      "Epoch 351/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0327\n",
      "Epoch 352/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0331\n",
      "Epoch 353/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0294\n",
      "Epoch 354/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0348\n",
      "Epoch 355/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0318\n",
      "Epoch 356/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0309\n",
      "Epoch 357/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0327\n",
      "Epoch 358/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0330\n",
      "Epoch 359/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0319\n",
      "Epoch 360/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0320\n",
      "Epoch 361/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0321\n",
      "Epoch 362/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0265\n",
      "Epoch 363/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0331\n",
      "Epoch 364/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0300\n",
      "Epoch 365/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0348\n",
      "Epoch 366/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0350\n",
      "Epoch 367/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0314\n",
      "Epoch 368/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0362\n",
      "Epoch 369/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0423\n",
      "Epoch 370/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0310\n",
      "Epoch 371/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0404\n",
      "Epoch 372/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0376\n",
      "Epoch 373/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0397\n",
      "Epoch 374/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0379\n",
      "Epoch 375/999\n",
      "----------\n",
      "train Loss: 0.0380\n",
      "Epoch 376/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0355\n",
      "Epoch 377/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0296\n",
      "Epoch 378/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0371\n",
      "Epoch 379/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0331\n",
      "Epoch 380/999\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffling the dataset\n",
      "train Loss: 0.0309\n",
      "Epoch 381/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0371\n",
      "Epoch 382/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0307\n",
      "Epoch 383/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0303\n",
      "Epoch 384/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0336\n",
      "Epoch 385/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0292\n",
      "Epoch 386/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0298\n",
      "Epoch 387/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0314\n",
      "Epoch 388/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0283\n",
      "Epoch 389/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0300\n",
      "Epoch 390/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0279\n",
      "Epoch 391/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0297\n",
      "Epoch 392/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0280\n",
      "Epoch 393/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0282\n",
      "Epoch 394/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0296\n",
      "Epoch 395/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0311\n",
      "Epoch 396/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0272\n",
      "Epoch 397/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0270\n",
      "Epoch 398/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0271\n",
      "Epoch 399/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0284\n",
      "Epoch 400/999\n",
      "----------\n",
      "train Loss: 0.0265\n",
      "Epoch 401/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0275\n",
      "Epoch 402/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0257\n",
      "Epoch 403/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0279\n",
      "Epoch 404/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0266\n",
      "Epoch 405/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0311\n",
      "Epoch 406/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0265\n",
      "Epoch 407/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0274\n",
      "Epoch 408/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0298\n",
      "Epoch 409/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0274\n",
      "Epoch 410/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0280\n",
      "Epoch 411/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0280\n",
      "Epoch 412/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0268\n",
      "Epoch 413/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0233\n",
      "Epoch 414/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0290\n",
      "Epoch 415/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0279\n",
      "Epoch 416/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0249\n",
      "Epoch 417/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0307\n",
      "Epoch 418/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0264\n",
      "Epoch 419/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0241\n",
      "Epoch 420/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0243\n",
      "Epoch 421/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0278\n",
      "Epoch 422/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0250\n",
      "Epoch 423/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0258\n",
      "Epoch 424/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0264\n",
      "Epoch 425/999\n",
      "----------\n",
      "train Loss: 0.0270\n",
      "Epoch 426/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0265\n",
      "Epoch 427/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0267\n",
      "Epoch 428/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0244\n",
      "Epoch 429/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0265\n",
      "Epoch 430/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0244\n",
      "Epoch 431/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0257\n",
      "Epoch 432/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0247\n",
      "Epoch 433/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0252\n",
      "Epoch 434/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0233\n",
      "Epoch 435/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0255\n",
      "Epoch 436/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0256\n",
      "Epoch 437/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0250\n",
      "Epoch 438/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0259\n",
      "Epoch 439/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0240\n",
      "Epoch 440/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0278\n",
      "Epoch 441/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0254\n",
      "Epoch 442/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0292\n",
      "Epoch 443/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0289\n",
      "Epoch 444/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0279\n",
      "Epoch 445/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0246\n",
      "Epoch 446/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0306\n",
      "Epoch 447/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0289\n",
      "Epoch 448/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0293\n",
      "Epoch 449/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0256\n",
      "Epoch 450/999\n",
      "----------\n",
      "train Loss: 0.0273\n",
      "Epoch 451/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0261\n",
      "Epoch 452/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0256\n",
      "Epoch 453/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0245\n",
      "Epoch 454/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0258\n",
      "Epoch 455/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0242\n",
      "Epoch 456/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0220\n",
      "Epoch 457/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0287\n",
      "Epoch 458/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0232\n",
      "Epoch 459/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0193\n",
      "Epoch 460/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0304\n",
      "Epoch 461/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0192\n",
      "Epoch 462/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0231\n",
      "Epoch 463/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0225\n",
      "Epoch 464/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0230\n",
      "Epoch 465/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0230\n",
      "Epoch 466/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0218\n",
      "Epoch 467/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0239\n",
      "Epoch 468/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0233\n",
      "Epoch 469/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0232\n",
      "Epoch 470/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0198\n",
      "Epoch 471/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0260\n",
      "Epoch 472/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0227\n",
      "Epoch 473/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0208\n",
      "Epoch 474/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0217\n",
      "Epoch 475/999\n",
      "----------\n",
      "train Loss: 0.0225\n",
      "Epoch 476/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0219\n",
      "Epoch 477/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0213\n",
      "Epoch 478/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0210\n",
      "Epoch 479/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0236\n",
      "Epoch 480/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0214\n",
      "Epoch 481/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0224\n",
      "Epoch 482/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0189\n",
      "Epoch 483/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0242\n",
      "Epoch 484/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0220\n",
      "Epoch 485/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0194\n",
      "Epoch 486/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0225\n",
      "Epoch 487/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0226\n",
      "Epoch 488/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0208\n",
      "Epoch 489/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0176\n",
      "Epoch 490/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0226\n",
      "Epoch 491/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0247\n",
      "Epoch 492/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0203\n",
      "Epoch 493/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0218\n",
      "Epoch 494/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0228\n",
      "Epoch 495/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0211\n",
      "Epoch 496/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0197\n",
      "Epoch 497/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0224\n",
      "Epoch 498/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0242\n",
      "Epoch 499/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0225\n",
      "Epoch 500/999\n",
      "----------\n",
      "train Loss: 0.0223\n",
      "Epoch 501/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0231\n",
      "Epoch 502/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0222\n",
      "Epoch 503/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0226\n",
      "Epoch 504/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0244\n",
      "Epoch 505/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0216\n",
      "Epoch 506/999\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffling the dataset\n",
      "train Loss: 0.0241\n",
      "Epoch 507/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0241\n",
      "Epoch 508/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0235\n",
      "Epoch 509/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0234\n",
      "Epoch 510/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0205\n",
      "Epoch 511/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0252\n",
      "Epoch 512/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0236\n",
      "Epoch 513/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0183\n",
      "Epoch 514/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0242\n",
      "Epoch 515/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0201\n",
      "Epoch 516/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0224\n",
      "Epoch 517/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0201\n",
      "Epoch 518/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0223\n",
      "Epoch 519/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0238\n",
      "Epoch 520/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0180\n",
      "Epoch 521/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0232\n",
      "Epoch 522/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0216\n",
      "Epoch 523/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0188\n",
      "Epoch 524/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0211\n",
      "Epoch 525/999\n",
      "----------\n",
      "train Loss: 0.0207\n",
      "Epoch 526/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0204\n",
      "Epoch 527/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0204\n",
      "Epoch 528/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0167\n",
      "Epoch 529/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0206\n",
      "Epoch 530/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0190\n",
      "Epoch 531/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0213\n",
      "Epoch 532/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0215\n",
      "Epoch 533/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0155\n",
      "Epoch 534/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0205\n",
      "Epoch 535/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0185\n",
      "Epoch 536/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0180\n",
      "Epoch 537/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0177\n",
      "Epoch 538/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0182\n",
      "Epoch 539/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0207\n",
      "Epoch 540/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0187\n",
      "Epoch 541/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0166\n",
      "Epoch 542/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0178\n",
      "Epoch 543/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0212\n",
      "Epoch 544/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0178\n",
      "Epoch 545/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0163\n",
      "Epoch 546/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0216\n",
      "Epoch 547/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0154\n",
      "Epoch 548/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0190\n",
      "Epoch 549/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0198\n",
      "Epoch 550/999\n",
      "----------\n",
      "train Loss: 0.0195\n",
      "Epoch 551/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0195\n",
      "Epoch 552/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0194\n",
      "Epoch 553/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0201\n",
      "Epoch 554/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0220\n",
      "Epoch 555/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0170\n",
      "Epoch 556/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0224\n",
      "Epoch 557/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0208\n",
      "Epoch 558/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0173\n",
      "Epoch 559/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0213\n",
      "Epoch 560/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0180\n",
      "Epoch 561/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0192\n",
      "Epoch 562/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0181\n",
      "Epoch 563/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0183\n",
      "Epoch 564/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0179\n",
      "Epoch 565/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0205\n",
      "Epoch 566/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0174\n",
      "Epoch 567/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0204\n",
      "Epoch 568/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0169\n",
      "Epoch 569/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0192\n",
      "Epoch 570/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0190\n",
      "Epoch 571/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0182\n",
      "Epoch 572/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0191\n",
      "Epoch 573/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0190\n",
      "Epoch 574/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0184\n",
      "Epoch 575/999\n",
      "----------\n",
      "train Loss: 0.0191\n",
      "Epoch 576/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0194\n",
      "Epoch 577/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0194\n",
      "Epoch 578/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0201\n",
      "Epoch 579/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0177\n",
      "Epoch 580/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0205\n",
      "Epoch 581/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0183\n",
      "Epoch 582/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0186\n",
      "Epoch 583/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0170\n",
      "Epoch 584/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0186\n",
      "Epoch 585/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0180\n",
      "Epoch 586/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0197\n",
      "Epoch 587/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0209\n",
      "Epoch 588/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0141\n",
      "Epoch 589/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0190\n",
      "Epoch 590/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0172\n",
      "Epoch 591/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0186\n",
      "Epoch 592/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0170\n",
      "Epoch 593/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0193\n",
      "Epoch 594/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0174\n",
      "Epoch 595/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0154\n",
      "Epoch 596/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0204\n",
      "Epoch 597/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0182\n",
      "Epoch 598/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0165\n",
      "Epoch 599/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0176\n",
      "Epoch 600/999\n",
      "----------\n",
      "train Loss: 0.0173\n",
      "Epoch 601/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0178\n",
      "Epoch 602/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0170\n",
      "Epoch 603/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0177\n",
      "Epoch 604/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0198\n",
      "Epoch 605/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0161\n",
      "Epoch 606/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0177\n",
      "Epoch 607/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0147\n",
      "Epoch 608/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0181\n",
      "Epoch 609/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0187\n",
      "Epoch 610/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0139\n",
      "Epoch 611/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0179\n",
      "Epoch 612/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0169\n",
      "Epoch 613/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0167\n",
      "Epoch 614/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0185\n",
      "Epoch 615/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0158\n",
      "Epoch 616/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0173\n",
      "Epoch 617/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0139\n",
      "Epoch 618/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0183\n",
      "Epoch 619/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0164\n",
      "Epoch 620/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0155\n",
      "Epoch 621/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0179\n",
      "Epoch 622/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0179\n",
      "Epoch 623/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0164\n",
      "Epoch 624/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0192\n",
      "Epoch 625/999\n",
      "----------\n",
      "train Loss: 0.0181\n",
      "Epoch 626/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0196\n",
      "Epoch 627/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0184\n",
      "Epoch 628/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0194\n",
      "Epoch 629/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0175\n",
      "Epoch 630/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0197\n",
      "Epoch 631/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0181\n",
      "Epoch 632/999\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffling the dataset\n",
      "train Loss: 0.0198\n",
      "Epoch 633/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0165\n",
      "Epoch 634/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0214\n",
      "Epoch 635/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0159\n",
      "Epoch 636/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0207\n",
      "Epoch 637/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0191\n",
      "Epoch 638/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0163\n",
      "Epoch 639/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0175\n",
      "Epoch 640/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0164\n",
      "Epoch 641/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0180\n",
      "Epoch 642/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0171\n",
      "Epoch 643/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0171\n",
      "Epoch 644/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0168\n",
      "Epoch 645/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0156\n",
      "Epoch 646/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0171\n",
      "Epoch 647/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0171\n",
      "Epoch 648/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0145\n",
      "Epoch 649/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0161\n",
      "Epoch 650/999\n",
      "----------\n",
      "train Loss: 0.0160\n",
      "Epoch 651/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0153\n",
      "Epoch 652/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0150\n",
      "Epoch 653/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0166\n",
      "Epoch 654/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0150\n",
      "Epoch 655/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0136\n",
      "Epoch 656/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0151\n",
      "Epoch 657/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0167\n",
      "Epoch 658/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0139\n",
      "Epoch 659/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0175\n",
      "Epoch 660/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0117\n",
      "Epoch 661/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0185\n",
      "Epoch 662/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0117\n",
      "Epoch 663/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0171\n",
      "Epoch 664/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0149\n",
      "Epoch 665/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0152\n",
      "Epoch 666/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0165\n",
      "Epoch 667/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0131\n",
      "Epoch 668/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0136\n",
      "Epoch 669/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0159\n",
      "Epoch 670/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0134\n",
      "Epoch 671/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0143\n",
      "Epoch 672/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0151\n",
      "Epoch 673/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0148\n",
      "Epoch 674/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0146\n",
      "Epoch 675/999\n",
      "----------\n",
      "train Loss: 0.0144\n",
      "Epoch 676/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0134\n",
      "Epoch 677/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0144\n",
      "Epoch 678/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0146\n",
      "Epoch 679/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0161\n",
      "Epoch 680/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0138\n",
      "Epoch 681/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0157\n",
      "Epoch 682/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0141\n",
      "Epoch 683/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0133\n",
      "Epoch 684/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0184\n",
      "Epoch 685/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0152\n",
      "Epoch 686/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0156\n",
      "Epoch 687/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0146\n",
      "Epoch 688/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0150\n",
      "Epoch 689/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0158\n",
      "Epoch 690/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0121\n",
      "Epoch 691/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0173\n",
      "Epoch 692/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0152\n",
      "Epoch 693/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0157\n",
      "Epoch 694/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0150\n",
      "Epoch 695/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0154\n",
      "Epoch 696/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0149\n",
      "Epoch 697/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0172\n",
      "Epoch 698/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0159\n",
      "Epoch 699/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0173\n",
      "Epoch 700/999\n",
      "----------\n",
      "train Loss: 0.0149\n",
      "Epoch 701/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0157\n",
      "Epoch 702/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0152\n",
      "Epoch 703/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0158\n",
      "Epoch 704/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0168\n",
      "Epoch 705/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0157\n",
      "Epoch 706/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0147\n",
      "Epoch 707/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0159\n",
      "Epoch 708/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0123\n",
      "Epoch 709/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0185\n",
      "Epoch 710/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0150\n",
      "Epoch 711/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0146\n",
      "Epoch 712/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0118\n",
      "Epoch 713/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0171\n",
      "Epoch 714/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0152\n",
      "Epoch 715/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0134\n",
      "Epoch 716/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0138\n",
      "Epoch 717/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0138\n",
      "Epoch 718/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0202\n",
      "Epoch 719/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0156\n",
      "Epoch 720/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0155\n",
      "Epoch 721/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0168\n",
      "Epoch 722/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0166\n",
      "Epoch 723/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0168\n",
      "Epoch 724/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0159\n",
      "Epoch 725/999\n",
      "----------\n",
      "train Loss: 0.0163\n",
      "Epoch 726/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0160\n",
      "Epoch 727/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0150\n",
      "Epoch 728/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0155\n",
      "Epoch 729/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0142\n",
      "Epoch 730/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0146\n",
      "Epoch 731/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0157\n",
      "Epoch 732/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0139\n",
      "Epoch 733/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0142\n",
      "Epoch 734/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0142\n",
      "Epoch 735/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0152\n",
      "Epoch 736/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0138\n",
      "Epoch 737/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0172\n",
      "Epoch 738/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0153\n",
      "Epoch 739/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0148\n",
      "Epoch 740/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0189\n",
      "Epoch 741/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0190\n",
      "Epoch 742/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0156\n",
      "Epoch 743/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0190\n",
      "Epoch 744/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0175\n",
      "Epoch 745/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0163\n",
      "Epoch 746/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0159\n",
      "Epoch 747/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0149\n",
      "Epoch 748/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0168\n",
      "Epoch 749/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0154\n",
      "Epoch 750/999\n",
      "----------\n",
      "train Loss: 0.0141\n",
      "Epoch 751/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0141\n",
      "Epoch 752/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0141\n",
      "Epoch 753/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0143\n",
      "Epoch 754/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0143\n",
      "Epoch 755/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0126\n",
      "Epoch 756/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0133\n",
      "Epoch 757/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0166\n",
      "Epoch 758/999\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffling the dataset\n",
      "train Loss: 0.0119\n",
      "Epoch 759/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0145\n",
      "Epoch 760/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0137\n",
      "Epoch 761/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0093\n",
      "Epoch 762/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0178\n",
      "Epoch 763/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0120\n",
      "Epoch 764/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0106\n",
      "Epoch 765/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0137\n",
      "Epoch 766/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0149\n",
      "Epoch 767/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0138\n",
      "Epoch 768/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0128\n",
      "Epoch 769/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0122\n",
      "Epoch 770/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0131\n",
      "Epoch 771/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0132\n",
      "Epoch 772/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0140\n",
      "Epoch 773/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0127\n",
      "Epoch 774/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0135\n",
      "Epoch 775/999\n",
      "----------\n",
      "train Loss: 0.0130\n",
      "Epoch 776/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0138\n",
      "Epoch 777/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0118\n",
      "Epoch 778/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0137\n",
      "Epoch 779/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0122\n",
      "Epoch 780/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0146\n",
      "Epoch 781/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0136\n",
      "Epoch 782/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0128\n",
      "Epoch 783/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0128\n",
      "Epoch 784/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0133\n",
      "Epoch 785/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0126\n",
      "Epoch 786/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0149\n",
      "Epoch 787/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0096\n",
      "Epoch 788/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0138\n",
      "Epoch 789/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0121\n",
      "Epoch 790/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0128\n",
      "Epoch 791/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0116\n",
      "Epoch 792/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0121\n",
      "Epoch 793/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0134\n",
      "Epoch 794/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0115\n",
      "Epoch 795/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0119\n",
      "Epoch 796/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0127\n",
      "Epoch 797/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0111\n",
      "Epoch 798/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0132\n",
      "Epoch 799/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0115\n",
      "Epoch 800/999\n",
      "----------\n",
      "train Loss: 0.0123\n",
      "Epoch 801/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0123\n",
      "Epoch 802/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0112\n",
      "Epoch 803/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0131\n",
      "Epoch 804/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0105\n",
      "Epoch 805/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0120\n",
      "Epoch 806/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0121\n",
      "Epoch 807/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0148\n",
      "Epoch 808/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0105\n",
      "Epoch 809/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0120\n",
      "Epoch 810/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0110\n",
      "Epoch 811/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0122\n",
      "Epoch 812/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0126\n",
      "Epoch 813/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0155\n",
      "Epoch 814/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0112\n",
      "Epoch 815/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0122\n",
      "Epoch 816/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0085\n",
      "Epoch 817/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0149\n",
      "Epoch 818/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0122\n",
      "Epoch 819/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0110\n",
      "Epoch 820/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0135\n",
      "Epoch 821/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0125\n",
      "Epoch 822/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0138\n",
      "Epoch 823/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0128\n",
      "Epoch 824/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0143\n",
      "Epoch 825/999\n",
      "----------\n",
      "train Loss: 0.0129\n",
      "Epoch 826/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0142\n",
      "Epoch 827/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0151\n",
      "Epoch 828/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0156\n",
      "Epoch 829/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0173\n",
      "Epoch 830/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0162\n",
      "Epoch 831/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0142\n",
      "Epoch 832/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0161\n",
      "Epoch 833/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0130\n",
      "Epoch 834/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0164\n",
      "Epoch 835/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0152\n",
      "Epoch 836/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0118\n",
      "Epoch 837/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0110\n",
      "Epoch 838/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0155\n",
      "Epoch 839/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0140\n",
      "Epoch 840/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0124\n",
      "Epoch 841/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0127\n",
      "Epoch 842/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0118\n",
      "Epoch 843/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0148\n",
      "Epoch 844/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0119\n",
      "Epoch 845/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0116\n",
      "Epoch 846/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0116\n",
      "Epoch 847/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0120\n",
      "Epoch 848/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0132\n",
      "Epoch 849/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0115\n",
      "Epoch 850/999\n",
      "----------\n",
      "train Loss: 0.0122\n",
      "Epoch 851/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0121\n",
      "Epoch 852/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0116\n",
      "Epoch 853/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0100\n",
      "Epoch 854/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0113\n",
      "Epoch 855/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0141\n",
      "Epoch 856/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0111\n",
      "Epoch 857/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0127\n",
      "Epoch 858/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0082\n",
      "Epoch 859/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0131\n",
      "Epoch 860/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0112\n",
      "Epoch 861/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0108\n",
      "Epoch 862/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0129\n",
      "Epoch 863/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0111\n",
      "Epoch 864/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0109\n",
      "Epoch 865/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0113\n",
      "Epoch 866/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0115\n",
      "Epoch 867/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0119\n",
      "Epoch 868/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0118\n",
      "Epoch 869/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0104\n",
      "Epoch 870/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0121\n",
      "Epoch 871/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0121\n",
      "Epoch 872/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0118\n",
      "Epoch 873/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0125\n",
      "Epoch 874/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0116\n",
      "Epoch 875/999\n",
      "----------\n",
      "train Loss: 0.0119\n",
      "Epoch 876/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0113\n",
      "Epoch 877/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0135\n",
      "Epoch 878/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0111\n",
      "Epoch 879/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0134\n",
      "Epoch 880/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0124\n",
      "Epoch 881/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0123\n",
      "Epoch 882/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0128\n",
      "Epoch 883/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0101\n",
      "Epoch 884/999\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffling the dataset\n",
      "train Loss: 0.0125\n",
      "Epoch 885/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0107\n",
      "Epoch 886/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0133\n",
      "Epoch 887/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0130\n",
      "Epoch 888/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0141\n",
      "Epoch 889/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0105\n",
      "Epoch 890/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0114\n",
      "Epoch 891/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0126\n",
      "Epoch 892/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0125\n",
      "Epoch 893/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0150\n",
      "Epoch 894/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0121\n",
      "Epoch 895/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0117\n",
      "Epoch 896/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0137\n",
      "Epoch 897/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0104\n",
      "Epoch 898/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0114\n",
      "Epoch 899/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0128\n",
      "Epoch 900/999\n",
      "----------\n",
      "train Loss: 0.0112\n",
      "Epoch 901/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0126\n",
      "Epoch 902/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0109\n",
      "Epoch 903/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0125\n",
      "Epoch 904/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0130\n",
      "Epoch 905/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0118\n",
      "Epoch 906/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0102\n",
      "Epoch 907/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0122\n",
      "Epoch 908/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0110\n",
      "Epoch 909/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0130\n",
      "Epoch 910/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0114\n",
      "Epoch 911/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0130\n",
      "Epoch 912/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0152\n",
      "Epoch 913/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0103\n",
      "Epoch 914/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0126\n",
      "Epoch 915/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0103\n",
      "Epoch 916/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0117\n",
      "Epoch 917/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0134\n",
      "Epoch 918/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0089\n",
      "Epoch 919/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0123\n",
      "Epoch 920/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0112\n",
      "Epoch 921/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0119\n",
      "Epoch 922/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0114\n",
      "Epoch 923/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0106\n",
      "Epoch 924/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0113\n",
      "Epoch 925/999\n",
      "----------\n",
      "train Loss: 0.0116\n",
      "Epoch 926/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0107\n",
      "Epoch 927/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0117\n",
      "Epoch 928/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0126\n",
      "Epoch 929/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0109\n",
      "Epoch 930/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0093\n",
      "Epoch 931/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0106\n",
      "Epoch 932/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0121\n",
      "Epoch 933/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0114\n",
      "Epoch 934/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0128\n",
      "Epoch 935/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0099\n",
      "Epoch 936/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0097\n",
      "Epoch 937/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0085\n",
      "Epoch 938/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0124\n",
      "Epoch 939/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0106\n",
      "Epoch 940/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0132\n",
      "Epoch 941/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0085\n",
      "Epoch 942/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0105\n",
      "Epoch 943/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0116\n",
      "Epoch 944/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0106\n",
      "Epoch 945/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0087\n",
      "Epoch 946/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0106\n",
      "Epoch 947/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0117\n",
      "Epoch 948/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0101\n",
      "Epoch 949/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0106\n",
      "Epoch 950/999\n",
      "----------\n",
      "train Loss: 0.0110\n",
      "Epoch 951/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0112\n",
      "Epoch 952/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0102\n",
      "Epoch 953/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0105\n",
      "Epoch 954/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0109\n",
      "Epoch 955/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0125\n",
      "Epoch 956/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0102\n",
      "Epoch 957/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0112\n",
      "Epoch 958/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0102\n",
      "Epoch 959/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0108\n",
      "Epoch 960/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0127\n",
      "Epoch 961/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0106\n",
      "Epoch 962/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0107\n",
      "Epoch 963/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0132\n",
      "Epoch 964/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0135\n",
      "Epoch 965/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0093\n",
      "Epoch 966/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0113\n",
      "Epoch 967/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0136\n",
      "Epoch 968/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0086\n",
      "Epoch 969/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0118\n",
      "Epoch 970/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0124\n",
      "Epoch 971/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0102\n",
      "Epoch 972/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0114\n",
      "Epoch 973/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0118\n",
      "Epoch 974/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0115\n",
      "Epoch 975/999\n",
      "----------\n",
      "train Loss: 0.0098\n",
      "Epoch 976/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0120\n",
      "Epoch 977/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0117\n",
      "Epoch 978/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0097\n",
      "Epoch 979/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0111\n",
      "Epoch 980/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0113\n",
      "Epoch 981/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0116\n",
      "Epoch 982/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0083\n",
      "Epoch 983/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0122\n",
      "Epoch 984/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0111\n",
      "Epoch 985/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0123\n",
      "Epoch 986/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0091\n",
      "Epoch 987/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0118\n",
      "Epoch 988/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0083\n",
      "Epoch 989/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0093\n",
      "Epoch 990/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0120\n",
      "Epoch 991/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0111\n",
      "Epoch 992/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0093\n",
      "Epoch 993/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0121\n",
      "Epoch 994/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0082\n",
      "Epoch 995/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0101\n",
      "Epoch 996/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0101\n",
      "Epoch 997/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0105\n",
      "Epoch 998/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0093\n",
      "Epoch 999/999\n",
      "----------\n",
      "shuffling the dataset\n",
      "train Loss: 0.0111\n"
     ]
    }
   ],
   "source": [
    "###################### Train Model #############################\n",
    "# Calculate total iter_num\n",
    "total_iter_num = 0\n",
    "\n",
    "for epoch in range(opt.num_epochs):\n",
    "    print('Epoch {}/{}'.format(epoch, opt.num_epochs - 1))\n",
    "    print('-' * 10)\n",
    "\n",
    "    # Each epoch has a training and validation phase\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    # Iterate over data.\n",
    "    for i in range(int(dataloader.size()/opt.batchSize)):\n",
    "        total_iter_num += 1\n",
    "        \n",
    "        # Get data\n",
    "        inputs, labels =  dataloader.get_batch()\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        #ToDo: get labels into correct format\n",
    "        \n",
    "        ## Create Graph ##\n",
    "        if graph_created == False:\n",
    "            graph_created = True\n",
    "            writer.add_graph(model, inputs, verbose=False)\n",
    "        \n",
    "        # Forward + Backward Prop\n",
    "        optimizer.zero_grad()\n",
    "        torch.set_grad_enabled(True)\n",
    "        normal_vectors = model(inputs)\n",
    "        normal_vectors_norm = nn.functional.normalize(normal_vectors, p=2, dim=1)\n",
    "        \n",
    "        loss = loss_fn(normal_vectors_norm, labels, reduction='elementwise_mean')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # statistics\n",
    "        running_loss += loss.item()\n",
    "        writer.add_scalar('running_loss', running_loss, total_iter_num)\n",
    "        writer.add_scalar('loss', loss.item(), total_iter_num)\n",
    "\n",
    "    epoch_loss = running_loss / (dataloader.size()/opt.batchSize)\n",
    "    print('{} Loss: {:.4f}'.format(phase, epoch_loss))\n",
    "    \n",
    "    # Save the model checkpoint\n",
    "    directory = opt.logs_path+'/checkpoints/'\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        \n",
    "    if (epoch % 10 == 0):\n",
    "        filename = opt.logs_path + '/checkpoints/checkpoint-ep_{}-iter_{}.pth'.format(epoch,i)\n",
    "        torch.save(model.state_dict(), filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark the speed\n",
    "\n",
    "Run the script below to get the estimate of fps you can achieve on your machine.\n",
    "For this experiment we used ```timeit``` magic function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'nyu_rgb_0782.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-0d0a111c56b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m                 ])\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mimg_not_preprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_not_preprocessed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch-cuda9.0/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2580\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2581\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'nyu_rgb_0782.png'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys, os\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "import models.resnet_dilated as resnet_dilated\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "img_path = 'nyu_rgb_0782.png'\n",
    "\n",
    "valid_transform = transforms.Compose(\n",
    "                [\n",
    "                     transforms.ToTensor(),\n",
    "                     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "                ])\n",
    "\n",
    "img_not_preprocessed = Image.open(img_path).convert('RGB').resize((224, 224))\n",
    "\n",
    "img = valid_transform(img_not_preprocessed)\n",
    "\n",
    "img = img.unsqueeze(0)\n",
    "\n",
    "img = Variable(img.cuda())\n",
    "\n",
    "fcn = unet.Unet(num_classes=opt.num_classes)\n",
    "fcn.load_state_dict(torch.load('checkpoints/checkpoint-458-32.pt'))\n",
    "fcn.cuda()\n",
    "fcn.eval()\n",
    "\n",
    "res = fcn(img)\n",
    "\n",
    "_, tmp = res.squeeze(0).max(0)\n",
    "print(tmp.shape)\n",
    "\n",
    "segmentation = tmp.data.cpu().numpy().squeeze()\n",
    "print(segmentation.shape)\n",
    "\n",
    "plt.imshow(img_not_preprocessed)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(segmentation.squeeze())\n",
    "plt.show()\n",
    "\n",
    "# tmp = res.squeeze(0).cpu()\n",
    "# print(tmp.data.numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_fcn():\n",
    "    \n",
    "    img = valid_transform(img_not_preprocessed)\n",
    "\n",
    "    img = img.unsqueeze(0)\n",
    "\n",
    "    img = Variable(img.cuda())\n",
    "    \n",
    "    res = fcn(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_not_preprocessed.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "# 50ms on a 512 by 512 image\n",
    "\n",
    "benchmark_fcn()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
