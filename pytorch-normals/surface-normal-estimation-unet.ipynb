{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./models/')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from data_loader import Dataset,Options\n",
    "import models.unet_normals as unet\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Options\n",
    "Set the various parameters:\n",
    "- dataroot: The folder where the training data is stored\n",
    "- file_list: List of filenames of images for training\n",
    "- batchSize: Batch size for model\n",
    "- shuffle: If true, will shuffle the dataset\n",
    "- phase: If 'train', then it's in training mode.\n",
    "- num_epochs: Number of epochs to train the model for\n",
    "- imsize: Dimensions of the image (square)\n",
    "- num_classes: Num of classes in the output\n",
    "- gpu: Which GPU device to use\n",
    "- logs_path: The path where the log files (tensorboard) will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OPT():\n",
    "    def __init__(self):\n",
    "        self.dataroot = './data/'\n",
    "        self.file_list = './data/datalist'\n",
    "        self.batchSize = 24\n",
    "        self.shuffle = True\n",
    "        self.phase = 'train'\n",
    "        self.num_epochs = 1000\n",
    "        self.imsize = 224\n",
    "        self.num_classes = int(3)\n",
    "        self.gpu = '0'\n",
    "        self.logs_path = 'logs/exp6'\n",
    "\n",
    "opt = OPT()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup logging and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffling the dataset\n"
     ]
    }
   ],
   "source": [
    "###################### Options #############################\n",
    "phase = opt.phase\n",
    "device = torch.device(\"cuda:\"+ opt.gpu if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "###################### TensorBoardX #############################\n",
    "writer = SummaryWriter(opt.logs_path, comment='create-graph')\n",
    "graph_created = False\n",
    "\n",
    "###################### DataLoader #############################\n",
    "dataloader = Dataset(opt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model\n",
    "We use a UNet model. The last few layers of this model are modified to return a 3 channel image, containing the x,y,z values of surface normal vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### ModelBuilder #############################\n",
    "model = unet.Unet(num_classes=opt.num_classes)\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "\n",
    "###################### Setup Optimazation #############################\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "###################### Loss fuction #############################\n",
    "'''\n",
    "@input: The 2 vectors whose cosine loss is to be calculated\n",
    "The dimensions of the matrices are expected to be (batchSize, 3, imsize, imsize). \n",
    "\n",
    "@return: \n",
    "elementwise_mean: will return the sum of all losses divided by num of elements\n",
    "none: The loss will be calculated to be of size (batchSize, imsize, imsize) containing cosine loss of each pixel\n",
    "'''\n",
    "def loss_fn(input_vec, target_vec, reduction='elementwise_mean'):\n",
    "    cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "    loss_val = 1.0 - cos(input_vec, target_vec)\n",
    "    if (reduction=='elementwise_mean'):\n",
    "        return torch.mean(loss_val)\n",
    "    elif (reduction=='none'):\n",
    "        return loss_val\n",
    "    else:\n",
    "        raise Exception('Warning! The reduction is invalid. Please use \\'elementwise_mean\\' or \\'none\\''.format())\n",
    "\n",
    "###################### Normalization fuction #############################\n",
    "# k = torch.tensor([[0.5, 0.1],[0.2,0.5]], dtype=torch.float)\n",
    "def norm_fn(target_vec):\n",
    "    nn.functional.normalize(target_vec, p=2, dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/999\n",
      "----------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "mul() received an invalid combination of arguments - got (NoneType), but expected one of:\n * (Tensor other)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mNoneType\u001b[0m)\n * (Number other)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mNoneType\u001b[0m)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a45481b64104>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mnormal_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormal_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormal_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'elementwise_mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-ad7e6cbb25fa>\u001b[0m in \u001b[0;36mloss_fn\u001b[0;34m(input_vec, target_vec, reduction)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'elementwise_mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mcos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCosineSimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'elementwise_mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch-cuda9.0/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch-cuda9.0/lib/python3.6/site-packages/torch/nn/modules/distance.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch-cuda9.0/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(x1, x2, dim, eps)\u001b[0m\n\u001b[1;32m   2215\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2216\u001b[0m     \"\"\"\n\u001b[0;32m-> 2217\u001b[0;31m     \u001b[0mw12\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2218\u001b[0m     \u001b[0mw1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2219\u001b[0m     \u001b[0mw2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: mul() received an invalid combination of arguments - got (NoneType), but expected one of:\n * (Tensor other)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mNoneType\u001b[0m)\n * (Number other)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mNoneType\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "###################### Train Model #############################\n",
    "# Calculate total iter_num\n",
    "total_iter_num = 0\n",
    "\n",
    "for epoch in range(opt.num_epochs):\n",
    "    print('Epoch {}/{}'.format(epoch, opt.num_epochs - 1))\n",
    "    print('-' * 10)\n",
    "\n",
    "    # Each epoch has a training and validation phase\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Iterate over data.\n",
    "    for i in range(int(dataloader.size()/opt.batchSize)):\n",
    "        total_iter_num += 1\n",
    "        \n",
    "        # Get data\n",
    "        inputs, labels =  dataloader.get_batch()\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        #ToDo: get labels into correct format\n",
    "        \n",
    "        ## Create Graph ##\n",
    "        if graph_created == False:\n",
    "            graph_created = True\n",
    "            writer.add_graph(model, inputs, verbose=False)\n",
    "\n",
    "        \n",
    "        # Forward + Backward Prop\n",
    "        optimizer.zero_grad()\n",
    "        torch.set_grad_enabled(True)\n",
    "        normal_vectors = model(inputs)\n",
    "        normal_vectors = norm_fn(normal_vectors)\n",
    "        \n",
    "        loss = loss_fn(normal_vectors, labels, reduction='elementwise_mean')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # statistics\n",
    "        running_loss += loss.item()\n",
    "        writer.add_scalar('running_loss', running_loss, total_iter_num)\n",
    "        writer.add_scalar('loss', loss.item(), total_iter_num)\n",
    "\n",
    "    epoch_loss = running_loss / dataloader.size()\n",
    "    print('{} Loss: {:.4f}'.format(phase, epoch_loss))\n",
    "    \n",
    "    # Save the model checkpoint\n",
    "    filename = 'checkpoints/checkpoint-{}-{}.pt'.format(epoch,i)\n",
    "    torch.save(model.state_dict(), filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[2, 3, 5],[float('NaN'),1,1]])\n",
    "print(x)\n",
    "print(x.size() )\n",
    "x = x.permute(1,0)\n",
    "\n",
    "print(x.contiguous().view(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark the speed\n",
    "\n",
    "Run the script below to get the estimate of fps you can achieve on your machine.\n",
    "For this experiment we used ```timeit``` magic function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys, os\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "import models.resnet_dilated as resnet_dilated\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "img_path = 'nyu_rgb_0782.png'\n",
    "\n",
    "valid_transform = transforms.Compose(\n",
    "                [\n",
    "                     transforms.ToTensor(),\n",
    "                     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "                ])\n",
    "\n",
    "img_not_preprocessed = Image.open(img_path).convert('RGB').resize((224, 224))\n",
    "\n",
    "img = valid_transform(img_not_preprocessed)\n",
    "\n",
    "img = img.unsqueeze(0)\n",
    "\n",
    "img = Variable(img.cuda())\n",
    "\n",
    "fcn = unet.Unet(num_classes=opt.num_classes)\n",
    "fcn.load_state_dict(torch.load('checkpoints/checkpoint-458-32.pt'))\n",
    "fcn.cuda()\n",
    "fcn.eval()\n",
    "\n",
    "res = fcn(img)\n",
    "\n",
    "_, tmp = res.squeeze(0).max(0)\n",
    "print(tmp.shape)\n",
    "\n",
    "segmentation = tmp.data.cpu().numpy().squeeze()\n",
    "print(segmentation.shape)\n",
    "\n",
    "plt.imshow(img_not_preprocessed)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(segmentation.squeeze())\n",
    "plt.show()\n",
    "\n",
    "# tmp = res.squeeze(0).cpu()\n",
    "# print(tmp.data.numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_fcn():\n",
    "    \n",
    "    img = valid_transform(img_not_preprocessed)\n",
    "\n",
    "    img = img.unsqueeze(0)\n",
    "\n",
    "    img = Variable(img.cuda())\n",
    "    \n",
    "    res = fcn(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_not_preprocessed.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "# 50ms on a 512 by 512 image\n",
    "\n",
    "benchmark_fcn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
