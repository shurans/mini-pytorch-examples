{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys, os\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "import models.unet_normals as unet\n",
    "import numpy as np\n",
    "from data_loader import Dataset,Options\n",
    "from skimage.transform import resize\n",
    "from skimage import img_as_uint\n",
    "\n",
    "\n",
    "###################### Loss fuction - Cosine #############################\n",
    "'''\n",
    "@input: The 2 vectors whose cosine loss is to be calculated\n",
    "The dimensions of the matrices are expected to be (batchSize, 3, imsize, imsize). \n",
    "\n",
    "@return: \n",
    "elementwise_mean: will return the sum of all losses divided by num of elements\n",
    "none: The loss will be calculated to be of size (batchSize, imsize, imsize) containing cosine loss of each pixel\n",
    "'''\n",
    "def loss_fn_cosine(input_vec, target_vec, reduction='elementwise_mean'):\n",
    "    cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "    loss_val = 1.0 - cos(input_vec, target_vec)\n",
    "    if (reduction=='elementwise_mean'):\n",
    "        return torch.mean(loss_val)\n",
    "    elif (reduction=='none'):\n",
    "        return loss_val\n",
    "    else:\n",
    "        raise Exception('Warning! The reduction is invalid. Please use \\'elementwise_mean\\' or \\'none\\''.format())\n",
    "\n",
    "###################### Loss fuction - Avg Angle Calc #############################\n",
    "'''\n",
    "@input: The 2 vectors whose cosine loss is to be calculated\n",
    "The dimensions of the matrices are expected to be (batchSize, 3, imsize, imsize). \n",
    "\n",
    "@return: \n",
    "elementwise_mean: will return the sum of all losses divided by num of elements\n",
    "none: The loss will be calculated to be of size (batchSize, imsize, imsize) containing cosine loss of each pixel\n",
    "'''\n",
    "def loss_fn_radians(input_vec, target_vec, reduction='elementwise_mean'):\n",
    "    cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "    loss_cos = cos(input_vec, target_vec)    \n",
    "    if (reduction=='elementwise_mean'):\n",
    "        return torch.acos(torch.mean(loss_cos))\n",
    "    elif (reduction=='none'):\n",
    "        return torch.acos(loss_cos)\n",
    "    else:\n",
    "        raise Exception('Warning! The reduction is invalid. Please use \\'elementwise_mean\\' or \\'none\\''.format())\n",
    "\n",
    "    return loss_val\n",
    "\n",
    "###################### Options #############################\n",
    "class OPT():\n",
    "    def __init__(self):\n",
    "        self.dataroot = './data/'\n",
    "        self.file_list = './data/datalist_test'\n",
    "        self.batchSize = 1\n",
    "        self.shuffle = False\n",
    "        self.phase = 'eval'\n",
    "        self.num_epochs = 1000\n",
    "        self.imsize = 224\n",
    "        self.num_classes = int(3)\n",
    "        self.gpu = '0'\n",
    "        self.logs_path = 'logs/exp10'\n",
    "\n",
    "opt = OPT()\n",
    "dataloader = Dataset(opt)\n",
    "\n",
    "# checkpoint_path = opt.logs_path + '/checkpoints/checkpoint-epoch_500.pth'\n",
    "checkpoint_path = 'logs_dl_playground/exp19/checkpoints/checkpoint-epoch_1000.pth'\n",
    "show_plots = True #True #False\n",
    "save_images = False\n",
    "\n",
    "device = torch.device(\"cuda:\"+ opt.gpu if torch.cuda.is_available() else \"cpu\")\n",
    "# Select Loss Func\n",
    "loss_fn = loss_fn_cosine\n",
    "\n",
    "\n",
    "##### Load Model #####\n",
    "model = unet.Unet(num_classes=opt.num_classes)\n",
    "model.load_state_dict(torch.load(checkpoint_path))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "##### Load Data #####\n",
    "running_loss = 0.0\n",
    "for i in range(int(dataloader.size()/opt.batchSize)): # BatchSize = 1\n",
    "    inputs, labels =  dataloader.get_batch() # Get tensor of image and camera normal\n",
    "    \n",
    "    inputs_orig = inputs.clone().squeeze(0)\n",
    "    labels_orig = labels.clone().squeeze(0).numpy()\n",
    "    \n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    normal_vectors = model(inputs)\n",
    "    normal_vectors_norm = nn.functional.normalize(normal_vectors, p=2, dim=1)\n",
    "    loss = loss_fn_cosine(normal_vectors_norm, labels, reduction='elementwise_mean')\n",
    "    running_loss += loss.item()\n",
    "    \n",
    "    loss_np = np.array([loss.item()], dtype=np.float32)\n",
    "    loss_rad = np.arccos(1-loss_np)\n",
    "    loss_deg = loss_rad * (180/np.pi)\n",
    "\n",
    "    print('Loss for img%03d is %0.4f = %.2f deg'%(i, loss.item(), loss_deg.item())) # round(loss.item(),6)\n",
    "    \n",
    "    ### Create Plots ##\n",
    "    if (show_plots):\n",
    "        # Input RGB Image\n",
    "        inv_normalize = transforms.Normalize( mean=[-0.485/0.229, -0.456/0.224, -0.406/0.255],\n",
    "                                              std=[1/0.229, 1/0.224, 1/0.255] )\n",
    "        rgb_img = inv_normalize(inputs_orig)\n",
    "        rgb_img = torch.clamp(rgb_img, min=0.0, max=1.0) #inv_norm isn't perfect. Some values out of range.\n",
    "        rgb_img = transforms.ToPILImage(mode='RGB')(rgb_img)\n",
    "        rgb_img = np.array(rgb_img)\n",
    "   \n",
    "        # Predicted Normals\n",
    "        output_norm = normal_vectors_norm.cpu()\n",
    "        output_norm = output_norm.squeeze(0).detach().numpy()\n",
    "        camera_normal_rgb = dataloader.normals_to_rgb_with_negatives(output_norm)\n",
    "        camera_normal_rgb = np.transpose(camera_normal_rgb, (1,2,0))\n",
    "\n",
    "        # Ground Truth Normals\n",
    "        truth_normal = labels_orig.transpose(1,2,0)\n",
    "        truth_normal = dataloader.normals_to_rgb_with_negatives(truth_normal)\n",
    "\n",
    "        fig = plt.figure(figsize=(12,12))\n",
    "        ax0 = plt.subplot(131)\n",
    "        ax1 = plt.subplot(132)\n",
    "        ax2 = plt.subplot(133)\n",
    "        ax0.imshow(rgb_img)\n",
    "        ax0.set_title('Source RGB Image') # subplot 211 title\n",
    "        ax1.imshow(camera_normal_rgb)\n",
    "        ax1.set_title('Predicted Normals')\n",
    "        ax2.imshow(truth_normal)\n",
    "        ax2.set_title('Ground Truth Normals')\n",
    "        plt.show()\n",
    "        plt.close('all')\n",
    "        \n",
    "    ### Save Images ###\n",
    "    if (save_images):\n",
    "        # Orig image\n",
    "        plt.imsave('data/results/test-results/%09d-rgb.png'%(i), rgb_img)\n",
    "\n",
    "        # Predicted Normals\n",
    "        plt.imsave('data/results/test-results/%09d-normals.png'%(i), camera_normal_rgb)\n",
    "\n",
    "        # Ground Truth Normals\n",
    "        plt.imsave('data/results/test-results/%09d-normals-groundtruth.png'%(i), truth_normal_resized)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "avg_loss = running_loss / (dataloader.size()/opt.batchSize) # BatchSize = 1\n",
    "print('Avg Loss of Test Set is: %0.4f = %03.2f deg'%(avg_loss, loss_deg.item()))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
