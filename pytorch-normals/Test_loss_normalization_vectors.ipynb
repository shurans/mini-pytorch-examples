{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surface Normal Model Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./models/')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test of Loss function for surface normal vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orig vector (only first one printed):\n",
      "tensor([[[[-0.8371,  1.5100,  2.0602, -0.6620,  0.8571],\n",
      "          [ 0.4888, -1.0918,  1.6563,  0.9894, -0.0242],\n",
      "          [-0.0954, -0.0485,  0.7650, -0.9491, -0.0061],\n",
      "          [-0.1170, -0.7213,  0.6771,  1.0299,  0.4900],\n",
      "          [ 0.6074, -0.4707,  1.2304,  0.5665, -2.0613]],\n",
      "\n",
      "         [[-0.6722,  0.8400,  0.5930, -1.2605, -0.5393],\n",
      "          [-0.3872,  0.4582,  0.1225,  0.5573, -0.1200],\n",
      "          [ 1.0336,  0.8583, -1.7595,  0.4496, -0.6732],\n",
      "          [ 0.8210,  0.5038,  0.1046, -0.8631,  0.3233],\n",
      "          [ 0.0631,  0.0158, -0.5698, -0.0013, -0.8978]],\n",
      "\n",
      "         [[-0.1006,  0.1529,  0.7249, -0.1935,  0.0963],\n",
      "          [ 0.0705,  0.8292,  1.3882,  1.0618, -0.8904],\n",
      "          [-0.3433,  0.3626,  0.1260, -0.3518, -2.6571],\n",
      "          [ 2.2381,  0.7644, -0.2176,  0.3785, -0.2013],\n",
      "          [ 1.1475,  0.0581, -0.5470,  0.0702,  0.5270]]],\n",
      "\n",
      "\n",
      "        [[[-1.4632, -0.4606,  1.0216, -0.3054,  0.6981],\n",
      "          [-1.3388, -1.1526, -0.2935, -1.6248, -0.7215],\n",
      "          [ 0.1127,  0.2520,  0.8913, -1.5580, -0.6025],\n",
      "          [ 0.7254,  1.5252, -0.1323,  0.4117, -0.2245],\n",
      "          [ 0.6929,  0.5983,  1.2576, -0.2790, -0.4913]],\n",
      "\n",
      "         [[-1.3514,  0.3254,  0.5555, -0.0189, -1.6579],\n",
      "          [-0.8699, -0.6808, -0.4830, -0.6045, -0.4378],\n",
      "          [-1.4708, -0.0090, -0.1341,  1.0175,  1.1961],\n",
      "          [ 0.5632,  1.5187,  0.1363, -0.4493,  0.1718],\n",
      "          [-0.0706, -0.8655,  2.0994,  0.2807, -0.7322]],\n",
      "\n",
      "         [[ 0.8794,  0.7251,  0.6239, -0.4251,  0.3928],\n",
      "          [-0.6074,  1.0485, -0.1649,  1.0477, -2.3362],\n",
      "          [-2.3622,  0.1790, -0.5362,  0.0940, -0.9065],\n",
      "          [ 0.6793,  1.9644, -0.5228,  1.2636,  0.9650],\n",
      "          [ 1.1553, -0.7307,  0.0620,  2.4827,  1.6592]]]])\n",
      "\n",
      "CosineEmbeddingLoss\n",
      "tensor([[[0.6714, 1.8632, 1.0036, 1.6528, 0.5679],\n",
      "         [1.7480, 0.6290, 0.8354, 0.0814, 0.2435],\n",
      "         [1.3792, 1.6163, 1.1504, 1.9795, 0.7246],\n",
      "         [1.6448, 0.7196, 0.5690, 1.1959, 1.6642],\n",
      "         [1.4308, 0.0528, 1.2862, 1.4171, 1.0859]],\n",
      "\n",
      "        [[0.7280, 1.4559, 1.6343, 0.1372, 1.0663],\n",
      "         [1.0643, 0.4492, 0.2769, 1.3881, 0.2451],\n",
      "         [0.4185, 0.8304, 1.3930, 1.3248, 1.6187],\n",
      "         [1.8975, 0.5236, 1.5451, 0.7899, 1.1380],\n",
      "         [0.2175, 0.3257, 0.5140, 0.4516, 0.0865]]])\n",
      "\n",
      "Cosine Similarity Matrix\n",
      "tensor([[[0.6714, 1.8632, 1.0036, 1.6528, 0.5679],\n",
      "         [1.7480, 0.6290, 0.8354, 0.0814, 0.2435],\n",
      "         [1.3792, 1.6163, 1.1504, 1.9795, 0.7246],\n",
      "         [1.6448, 0.7196, 0.5690, 1.1959, 1.6642],\n",
      "         [1.4308, 0.0528, 1.2862, 1.4171, 1.0859]],\n",
      "\n",
      "        [[0.7280, 1.4559, 1.6343, 0.1372, 1.0663],\n",
      "         [1.0643, 0.4492, 0.2769, 1.3881, 0.2451],\n",
      "         [0.4185, 0.8304, 1.3930, 1.3248, 1.6187],\n",
      "         [1.8975, 0.5236, 1.5451, 0.7899, 1.1380],\n",
      "         [0.2175, 0.3257, 0.5140, 0.4516, 0.0865]]])\n",
      "Cosine Similarity mean loss\n",
      "tensor(0.9747)\n"
     ]
    }
   ],
   "source": [
    "# x = torch.autograd.Variable(torch.randn(3, 5) )\n",
    "# y = torch.autograd.Variable(torch.randn(3, 5) )\n",
    "x = torch.autograd.Variable(torch.randn(2, 3, 5, 5) )\n",
    "y = torch.autograd.Variable(torch.randn(2, 3, 5, 5) )\n",
    "print('Orig vector (only first one printed):')\n",
    "print(x)\n",
    "target2 = torch.autograd.Variable(torch.tensor([1], dtype=torch.float))\n",
    "\n",
    "#CosineEmbeddingLoss\n",
    "loss_fn = torch.nn.CosineEmbeddingLoss(reduction='none') #NOTE: elementwise_mean apparently doesn't work\n",
    "z0 = loss_fn(x, y, target2)\n",
    "print('\\nCosineEmbeddingLoss')\n",
    "print(z0)\n",
    "\n",
    "#CosineSimilarity\n",
    "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "loss_fn = 1 - cos(x,y)\n",
    "print('\\nCosine Similarity Matrix')\n",
    "print(loss_fn)\n",
    "loss_fn_mean = torch.mean( loss_fn )\n",
    "print('Cosine Similarity mean loss')\n",
    "print(loss_fn_mean)\n",
    "        \n",
    "\n",
    "#Custom Code\n",
    "# a = (x.norm(p=2,dim=0)*y.norm(p=2,dim=0))\n",
    "# b = torch.sum(x*y,1)\n",
    "# a[a==0] = 1\n",
    "# b[a==0] = 1\n",
    "# distance = 1 - ( b / a)\n",
    "# totloss = torch.mean(distance)\n",
    "# print('\\nShuran\\'s Loss func')\n",
    "# print(totloss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test of Normalization Function for surface normal vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss matrix dimensions:\n",
      "torch.Size([2, 5, 5])\n",
      "\n",
      "Normalized Tensor, along dim 1 (column):\n",
      "tensor([[[0.6780, 0.7880, 0.5233, 0.9966, 0.4701],\n",
      "         [0.8541, 0.8137, 0.9492, 0.0585, 0.7046],\n",
      "         [0.9569, 0.8895, 0.6367, 0.8311, 0.4086],\n",
      "         [0.6550, 0.8086, 0.3456, 0.8344, 0.8255],\n",
      "         [0.9886, 0.1599, 0.9286, 0.9528, 0.9968]],\n",
      "\n",
      "        [[0.7351, 0.6157, 0.8522, 0.0827, 0.8826],\n",
      "         [0.5200, 0.5812, 0.3146, 0.9983, 0.7096],\n",
      "         [0.2904, 0.4570, 0.7711, 0.5562, 0.9127],\n",
      "         [0.7556, 0.5884, 0.9384, 0.5511, 0.5645],\n",
      "         [0.1503, 0.9871, 0.3711, 0.3036, 0.0794]]])\n"
     ]
    }
   ],
   "source": [
    "print('Loss matrix dimensions:')\n",
    "print(loss_fn.size())\n",
    "print('\\nNormalized Tensor, along dim 1 (column):')\n",
    "print(nn.functional.normalize(loss_fn, p=2, dim=0))\n",
    "\n",
    "# k = torch.tensor([[0.5, 0.1],[0.2,0.5]], dtype=torch.float)\n",
    "# print('Tensor k:')\n",
    "# print(k)\n",
    "# print('\\nNormalized Tensor, along dim 1 (column):')\n",
    "# print(nn.functional.normalize(k, p=2, dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read EXR Files\n",
    "\n",
    "### OpenEXR - Single Channel\n",
    "This method uses the OpenEXR library to read in the EXR files. How to load in single channel (depth):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0) - (1919, 1079)\n",
      "(1080, 1920)\n"
     ]
    }
   ],
   "source": [
    "import OpenEXR, Imath\n",
    "EXR_PATH = '/media/shrek/work/datasets/greppy-surface-normals-bottle/normals_masks/000000000-normals.exr'\n",
    "exr_file = OpenEXR.InputFile(EXR_PATH)\n",
    "\n",
    "cm_dw = exr_file.header()['dataWindow']\n",
    "render_depth = np.frombuffer(\n",
    "    exr_file.channel('R', Imath.PixelType(Imath.PixelType.HALF)),\n",
    "    dtype=np.float16\n",
    ")\n",
    "\n",
    "render_depth.shape = (cm_dw.max.y - cm_dw.min.y + 1, cm_dw.max.x - cm_dw.min.x + 1) # rows, cols\n",
    "\n",
    "print(cm_dw)\n",
    "print(render_depth.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenEXR - 3 Channels\n",
    "How to load in 3 channels (surface normal):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1080, 1920)\n"
     ]
    }
   ],
   "source": [
    "def exr_loader(path, ndim=3):\n",
    "    \"\"\"\n",
    "    loads an .exr file as a numpy array\n",
    "    :param path: path to the file\n",
    "    :param ndim: number of channels that the image has,\n",
    "                    if 1 the 'R' channel is taken\n",
    "                    if 3 the 'R', 'G' and 'B' channels are taken\n",
    "    :return: np.array containing the .exr image\n",
    "    \"\"\"\n",
    "\n",
    "    exr_file = OpenEXR.InputFile(EXR_PATH)\n",
    "    cm_dw = exr_file.header()['dataWindow']\n",
    "    size = (cm_dw.max.x - cm_dw.min.x + 1, cm_dw.max.y - cm_dw.min.y + 1)\n",
    "\n",
    "    pt = Imath.PixelType(Imath.PixelType.FLOAT)\n",
    "\n",
    "    if ndim == 3:\n",
    "        # read channels indivudally\n",
    "        allchannels = []\n",
    "        for c in ['R', 'G', 'B']:\n",
    "            # transform data to numpy\n",
    "            channel = np.frombuffer(exr_file.channel(c, pt), dtype=np.float32)\n",
    "            channel.shape = (size[1], size[0])\n",
    "            allchannels.append(channel)\n",
    "\n",
    "        # create array and transpose dimensions to match numpy style\n",
    "        exr_arr = np.array(allchannels).transpose((0, 1, 2)) \n",
    "        return exr_arr\n",
    "    \n",
    "    if ndim == 1:\n",
    "        # transform data to numpy\n",
    "        channel = np.fromstring(channel=pic.channel('R', pt), dtype=np.float32)\n",
    "        channel.shape = (size[1], size[0])  # Numpy arrays are (row, col)\n",
    "        exr_arr = np.array(channel)\n",
    "        return exr_arr\n",
    "\n",
    "im = exr_loader(EXR_PATH, ndim=3)\n",
    "print(im.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing EXR numpy array\n",
    "It will output a tensor which is scaled to a given size and converted to a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__call__() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-39b54901d0d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToPILImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'F'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformLabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# print(label.type)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __call__() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms, utils\n",
    "from PIL import Image\n",
    "\n",
    "imsize = 224\n",
    "\n",
    "def transformLabel(label):\n",
    "        transform_list = []\n",
    "        transform_list.append(transforms.Resize([imsize, imsize]))\n",
    "        transform_list.append(transforms.ToTensor())\n",
    "        tf = transforms.Compose(transform_list)\n",
    "        label = tf(label)\n",
    "        return label\n",
    "\n",
    "label = torch.from_numpy(im)\n",
    "label = transforms.ToPILImage()(label, 'F')\n",
    "label = transformLabel(label)\n",
    "# print(label.type)\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
